"""Phase 2: Convert CCNL models to SQLModel (14 models)

Revision ID: 6c9df3d39110
Revises: 20251126_add_query_signature
Create Date: 2025-11-28 12:49:19.542076

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '6c9df3d39110'
down_revision: Union[str, Sequence[str], None] = '20251126_add_query_signature'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('ccnl_database',
    sa.Column('id', sa.Uuid(), nullable=False),
    sa.Column('sector_name', sqlmodel.sql.sqltypes.AutoString(length=200), nullable=False),
    sa.Column('ccnl_code', sqlmodel.sql.sqltypes.AutoString(length=50), nullable=False),
    sa.Column('official_name', sa.Text(), nullable=False),
    sa.Column('current_version_id', sa.Uuid(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('updated_at', sa.DateTime(), nullable=False),
    sa.Column('is_active', sa.Boolean(), nullable=False),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('ccnl_code')
    )
    op.create_index('idx_ccnl_database_active', 'ccnl_database', ['is_active'], unique=False)
    op.create_index('idx_ccnl_database_code', 'ccnl_database', ['ccnl_code'], unique=False)
    op.create_index('idx_ccnl_database_sector', 'ccnl_database', ['sector_name'], unique=False)
    op.create_table('ccnl_monitoring_metrics',
    sa.Column('id', sa.Uuid(), nullable=False),
    sa.Column('metric_type', sqlmodel.sql.sqltypes.AutoString(length=50), nullable=False),
    sa.Column('metric_name', sqlmodel.sql.sqltypes.AutoString(length=100), nullable=False),
    sa.Column('value', sa.Numeric(precision=10, scale=4), nullable=False),
    sa.Column('unit', sqlmodel.sql.sqltypes.AutoString(length=20), nullable=True),
    sa.Column('timestamp', sa.DateTime(), nullable=False),
    sa.Column('source', sqlmodel.sql.sqltypes.AutoString(length=50), nullable=True),
    sa.Column('metric_metadata', sa.JSON(), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_monitoring_metrics_timestamp', 'ccnl_monitoring_metrics', ['timestamp'], unique=False)
    op.create_index('idx_monitoring_metrics_type', 'ccnl_monitoring_metrics', ['metric_type'], unique=False)
    op.create_table('ccnl_sectors',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('sector_code', sqlmodel.sql.sqltypes.AutoString(length=50), nullable=False),
    sa.Column('italian_name', sqlmodel.sql.sqltypes.AutoString(length=200), nullable=False),
    sa.Column('priority_level', sa.Integer(), nullable=False),
    sa.Column('worker_coverage_percentage', sa.Numeric(precision=5, scale=2), nullable=True),
    sa.Column('active', sa.Boolean(), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.CheckConstraint('priority_level >= 1 AND priority_level <= 6', name='valid_priority_level'),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_ccnl_sectors_priority_active', 'ccnl_sectors', ['priority_level', 'active'], unique=False)
    op.create_index(op.f('ix_ccnl_sectors_sector_code'), 'ccnl_sectors', ['sector_code'], unique=True)
    op.create_table('ccnl_agreements',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('sector_code', sqlmodel.sql.sqltypes.AutoString(length=50), nullable=False),
    sa.Column('name', sqlmodel.sql.sqltypes.AutoString(length=500), nullable=False),
    sa.Column('valid_from', sa.Date(), nullable=False),
    sa.Column('valid_to', sa.Date(), nullable=True),
    sa.Column('signatory_unions', sa.JSON(), nullable=True),
    sa.Column('signatory_employers', sa.JSON(), nullable=True),
    sa.Column('renewal_status', sqlmodel.sql.sqltypes.AutoString(length=20), nullable=False),
    sa.Column('last_updated', sa.DateTime(), nullable=True),
    sa.Column('data_source', sqlmodel.sql.sqltypes.AutoString(length=500), nullable=True),
    sa.Column('verification_date', sa.Date(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['sector_code'], ['ccnl_sectors.sector_code'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_ccnl_agreements_dates', 'ccnl_agreements', ['valid_from', 'valid_to'], unique=False)
    op.create_index('idx_ccnl_agreements_sector_valid', 'ccnl_agreements', ['sector_code', 'valid_from', 'valid_to'], unique=False)
    op.create_table('ccnl_update_events',
    sa.Column('id', sa.Uuid(), nullable=False),
    sa.Column('ccnl_id', sa.Uuid(), nullable=False),
    sa.Column('source', sqlmodel.sql.sqltypes.AutoString(length=50), nullable=False),
    sa.Column('detected_at', sa.DateTime(), nullable=False),
    sa.Column('title', sa.Text(), nullable=False),
    sa.Column('url', sa.Text(), nullable=True),
    sa.Column('content_summary', sa.Text(), nullable=True),
    sa.Column('classification_confidence', sa.Numeric(precision=3, scale=2), nullable=False),
    sa.Column('status', sqlmodel.sql.sqltypes.AutoString(length=20), nullable=False),
    sa.Column('processed_at', sa.DateTime(), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.ForeignKeyConstraint(['ccnl_id'], ['ccnl_database.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_update_events_ccnl_id', 'ccnl_update_events', ['ccnl_id'], unique=False)
    op.create_index('idx_update_events_detected', 'ccnl_update_events', ['detected_at'], unique=False)
    op.create_index('idx_update_events_status', 'ccnl_update_events', ['status'], unique=False)
    op.create_table('ccnl_versions',
    sa.Column('id', sa.Uuid(), nullable=False),
    sa.Column('ccnl_id', sa.Uuid(), nullable=False),
    sa.Column('version_number', sqlmodel.sql.sqltypes.AutoString(length=20), nullable=False),
    sa.Column('effective_date', sa.Date(), nullable=False),
    sa.Column('expiry_date', sa.Date(), nullable=True),
    sa.Column('signed_date', sa.Date(), nullable=True),
    sa.Column('document_url', sa.Text(), nullable=True),
    sa.Column('salary_data', sa.JSON(), nullable=False),
    sa.Column('working_conditions', sa.JSON(), nullable=False),
    sa.Column('leave_provisions', sa.JSON(), nullable=False),
    sa.Column('other_benefits', sa.JSON(), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('is_current', sa.Boolean(), nullable=False),
    sa.ForeignKeyConstraint(['ccnl_id'], ['ccnl_database.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_ccnl_versions_ccnl_id', 'ccnl_versions', ['ccnl_id'], unique=False)
    op.create_index('idx_ccnl_versions_current', 'ccnl_versions', ['is_current'], unique=False)
    op.create_index('idx_ccnl_versions_effective', 'ccnl_versions', ['effective_date'], unique=False)
    op.create_table('ccnl_change_logs',
    sa.Column('id', sa.Uuid(), nullable=False),
    sa.Column('ccnl_id', sa.Uuid(), nullable=False),
    sa.Column('old_version_id', sa.Uuid(), nullable=True),
    sa.Column('new_version_id', sa.Uuid(), nullable=False),
    sa.Column('change_type', sqlmodel.sql.sqltypes.AutoString(length=20), nullable=False),
    sa.Column('changes_summary', sa.Text(), nullable=False),
    sa.Column('detailed_changes', sa.JSON(), nullable=False),
    sa.Column('significance_score', sa.Numeric(precision=3, scale=2), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('created_by', sqlmodel.sql.sqltypes.AutoString(length=100), nullable=True),
    sa.ForeignKeyConstraint(['ccnl_id'], ['ccnl_database.id'], ),
    sa.ForeignKeyConstraint(['new_version_id'], ['ccnl_versions.id'], ),
    sa.ForeignKeyConstraint(['old_version_id'], ['ccnl_versions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_change_logs_ccnl_id', 'ccnl_change_logs', ['ccnl_id'], unique=False)
    op.create_index('idx_change_logs_created', 'ccnl_change_logs', ['created_at'], unique=False)
    op.create_index('idx_change_logs_significance', 'ccnl_change_logs', ['significance_score'], unique=False)
    op.create_table('ccnl_job_levels',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('agreement_id', sa.Integer(), nullable=False),
    sa.Column('level_code', sqlmodel.sql.sqltypes.AutoString(length=10), nullable=False),
    sa.Column('level_name', sqlmodel.sql.sqltypes.AutoString(length=200), nullable=False),
    sa.Column('worker_category', sqlmodel.sql.sqltypes.AutoString(length=20), nullable=False),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('minimum_experience_months', sa.Integer(), nullable=False),
    sa.Column('required_qualifications', sa.JSON(), nullable=True),
    sa.Column('typical_tasks', sa.JSON(), nullable=True),
    sa.Column('decision_making_level', sqlmodel.sql.sqltypes.AutoString(length=50), nullable=True),
    sa.Column('supervision_responsibilities', sa.Boolean(), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['agreement_id'], ['ccnl_agreements.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_job_levels_agreement_code', 'ccnl_job_levels', ['agreement_id', 'level_code'], unique=False)
    op.create_index('idx_job_levels_category', 'ccnl_job_levels', ['worker_category'], unique=False)
    op.create_table('ccnl_leave_entitlements',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('agreement_id', sa.Integer(), nullable=False),
    sa.Column('leave_type', sqlmodel.sql.sqltypes.AutoString(length=50), nullable=False),
    sa.Column('base_annual_days', sa.Integer(), nullable=True),
    sa.Column('base_annual_hours', sa.Integer(), nullable=True),
    sa.Column('seniority_bonus_schedule', sa.JSON(), nullable=True),
    sa.Column('calculation_method', sqlmodel.sql.sqltypes.AutoString(length=20), nullable=False),
    sa.Column('minimum_usage_hours', sa.Integer(), nullable=True),
    sa.Column('advance_notice_hours', sa.Integer(), nullable=True),
    sa.Column('compensation_percentage', sa.Numeric(precision=4, scale=2), nullable=True),
    sa.Column('mandatory_period', sa.Boolean(), nullable=False),
    sa.Column('additional_optional_days', sa.Integer(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.CheckConstraint('compensation_percentage >= 0 AND compensation_percentage <= 1', name='valid_compensation'),
    sa.ForeignKeyConstraint(['agreement_id'], ['ccnl_agreements.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_leave_entitlements_agreement_type', 'ccnl_leave_entitlements', ['agreement_id', 'leave_type'], unique=False)
    op.create_table('ccnl_notice_periods',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('agreement_id', sa.Integer(), nullable=False),
    sa.Column('worker_category', sqlmodel.sql.sqltypes.AutoString(length=20), nullable=False),
    sa.Column('seniority_months_min', sa.Integer(), nullable=False),
    sa.Column('seniority_months_max', sa.Integer(), nullable=False),
    sa.Column('notice_days', sa.Integer(), nullable=False),
    sa.Column('termination_by', sqlmodel.sql.sqltypes.AutoString(length=10), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.CheckConstraint('notice_days > 0', name='positive_notice_days'),
    sa.CheckConstraint('seniority_months_max >= seniority_months_min', name='valid_seniority_range'),
    sa.ForeignKeyConstraint(['agreement_id'], ['ccnl_agreements.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_notice_periods_agreement_category', 'ccnl_notice_periods', ['agreement_id', 'worker_category'], unique=False)
    op.create_table('ccnl_overtime_rules',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('agreement_id', sa.Integer(), nullable=False),
    sa.Column('daily_threshold_hours', sa.Integer(), nullable=False),
    sa.Column('weekly_threshold_hours', sa.Integer(), nullable=False),
    sa.Column('daily_overtime_rate', sa.Numeric(precision=4, scale=2), nullable=True),
    sa.Column('weekend_rate', sa.Numeric(precision=4, scale=2), nullable=True),
    sa.Column('holiday_rate', sa.Numeric(precision=4, scale=2), nullable=True),
    sa.Column('maximum_daily_overtime', sa.Integer(), nullable=True),
    sa.Column('maximum_weekly_overtime', sa.Integer(), nullable=True),
    sa.Column('maximum_monthly_overtime', sa.Integer(), nullable=True),
    sa.Column('maximum_annual_overtime', sa.Integer(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.CheckConstraint('daily_overtime_rate >= 1.0', name='valid_overtime_rate'),
    sa.ForeignKeyConstraint(['agreement_id'], ['ccnl_agreements.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_overtime_rules_agreement', 'ccnl_overtime_rules', ['agreement_id'], unique=False)
    op.create_table('ccnl_salary_tables',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('agreement_id', sa.Integer(), nullable=False),
    sa.Column('level_code', sqlmodel.sql.sqltypes.AutoString(length=10), nullable=False),
    sa.Column('base_monthly_salary', sa.Numeric(precision=10, scale=2), nullable=False),
    sa.Column('geographic_area', sqlmodel.sql.sqltypes.AutoString(length=20), nullable=False),
    sa.Column('valid_from', sa.Date(), nullable=True),
    sa.Column('valid_to', sa.Date(), nullable=True),
    sa.Column('thirteenth_month', sa.Boolean(), nullable=False),
    sa.Column('fourteenth_month', sa.Boolean(), nullable=False),
    sa.Column('additional_allowances', sa.JSON(), nullable=True),
    sa.Column('company_size_adjustments', sa.JSON(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.CheckConstraint('base_monthly_salary > 0', name='positive_salary'),
    sa.ForeignKeyConstraint(['agreement_id'], ['ccnl_agreements.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_salary_tables_agreement_level', 'ccnl_salary_tables', ['agreement_id', 'level_code', 'geographic_area'], unique=False)
    op.create_index('idx_salary_tables_dates', 'ccnl_salary_tables', ['valid_from', 'valid_to'], unique=False)
    op.create_table('ccnl_special_allowances',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('agreement_id', sa.Integer(), nullable=False),
    sa.Column('allowance_type', sqlmodel.sql.sqltypes.AutoString(length=50), nullable=False),
    sa.Column('amount', sa.Numeric(precision=8, scale=2), nullable=False),
    sa.Column('frequency', sqlmodel.sql.sqltypes.AutoString(length=10), nullable=False),
    sa.Column('conditions', sa.JSON(), nullable=True),
    sa.Column('applicable_job_levels', sa.JSON(), nullable=True),
    sa.Column('geographic_areas', sa.JSON(), nullable=True),
    sa.Column('company_sizes', sa.JSON(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.CheckConstraint('amount > 0', name='positive_allowance_amount'),
    sa.ForeignKeyConstraint(['agreement_id'], ['ccnl_agreements.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_special_allowances_agreement_type', 'ccnl_special_allowances', ['agreement_id', 'allowance_type'], unique=False)
    op.create_table('ccnl_working_hours',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('agreement_id', sa.Integer(), nullable=False),
    sa.Column('ordinary_weekly_hours', sa.Integer(), nullable=False),
    sa.Column('maximum_weekly_hours', sa.Integer(), nullable=False),
    sa.Column('daily_rest_hours', sa.Integer(), nullable=False),
    sa.Column('weekly_rest_hours', sa.Integer(), nullable=False),
    sa.Column('flexible_hours_allowed', sa.Boolean(), nullable=False),
    sa.Column('flexible_hours_range_min', sa.Integer(), nullable=True),
    sa.Column('flexible_hours_range_max', sa.Integer(), nullable=True),
    sa.Column('core_hours_start', sqlmodel.sql.sqltypes.AutoString(length=5), nullable=True),
    sa.Column('core_hours_end', sqlmodel.sql.sqltypes.AutoString(length=5), nullable=True),
    sa.Column('part_time_allowed', sa.Boolean(), nullable=False),
    sa.Column('minimum_part_time_hours', sa.Integer(), nullable=True),
    sa.Column('shift_work_allowed', sa.Boolean(), nullable=False),
    sa.Column('shift_patterns', sa.JSON(), nullable=True),
    sa.Column('night_shift_allowance', sa.Numeric(precision=6, scale=2), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.CheckConstraint('maximum_weekly_hours >= ordinary_weekly_hours', name='max_hours_valid'),
    sa.CheckConstraint('ordinary_weekly_hours > 0', name='positive_weekly_hours'),
    sa.ForeignKeyConstraint(['agreement_id'], ['ccnl_agreements.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_working_hours_agreement', 'ccnl_working_hours', ['agreement_id'], unique=False)
    op.drop_index(op.f('checkpoints_thread_id_idx'), table_name='checkpoints')
    op.drop_table('checkpoints')
    op.drop_index(op.f('idx_expert_feedback_expert_id'), table_name='expert_feedback')
    op.drop_index(op.f('idx_expert_feedback_generated_faq_id'), table_name='expert_feedback')
    op.drop_index(op.f('idx_expert_feedback_improvement_applied'), table_name='expert_feedback', postgresql_where='(improvement_applied = false)')
    op.drop_index(op.f('idx_expert_feedback_query_id'), table_name='expert_feedback')
    op.drop_index(op.f('idx_expert_feedback_task_id'), table_name='expert_feedback', postgresql_where='(generated_task_id IS NOT NULL)')
    op.drop_index(op.f('idx_expert_feedback_timestamp'), table_name='expert_feedback')
    op.drop_index(op.f('idx_expert_feedback_type_category'), table_name='expert_feedback')
    op.drop_table('expert_feedback')
    op.drop_table('checkpoint_migrations')
    op.drop_index(op.f('idx_expert_faq_candidates_category'), table_name='expert_faq_candidates')
    op.drop_index(op.f('idx_expert_faq_candidates_expert'), table_name='expert_faq_candidates')
    op.drop_index(op.f('idx_expert_faq_candidates_priority'), table_name='expert_faq_candidates')
    op.drop_index(op.f('idx_expert_faq_candidates_status'), table_name='expert_faq_candidates')
    op.drop_index(op.f('idx_expert_faq_question_embedding_ivfflat'), table_name='expert_faq_candidates', postgresql_with={'lists': '100'}, postgresql_using='ivfflat')
    op.drop_table('expert_faq_candidates')
    op.drop_index(op.f('checkpoint_writes_thread_id_idx'), table_name='checkpoint_writes')
    op.drop_table('checkpoint_writes')
    op.drop_index(op.f('checkpoint_blobs_thread_id_idx'), table_name='checkpoint_blobs')
    op.drop_table('checkpoint_blobs')
    op.drop_index(op.f('idx_expert_profiles_active'), table_name='expert_profiles')
    op.drop_index(op.f('idx_expert_profiles_specializations'), table_name='expert_profiles', postgresql_using='gin')
    op.drop_index(op.f('idx_expert_profiles_trust_score'), table_name='expert_profiles')
    op.drop_table('expert_profiles')
    op.drop_index(op.f('idx_egt_created_at'), table_name='expert_generated_tasks')
    op.drop_index(op.f('idx_egt_expert_id'), table_name='expert_generated_tasks')
    op.drop_index(op.f('idx_egt_feedback_id'), table_name='expert_generated_tasks')
    op.drop_index(op.f('idx_egt_task_id'), table_name='expert_generated_tasks')
    op.drop_table('expert_generated_tasks')
    op.alter_column('cost_alerts', 'user_id',
               existing_type=sa.VARCHAR(),
               type_=sa.Integer(),
               existing_nullable=True)
    op.create_foreign_key(None, 'cost_alerts', 'user', ['user_id'], ['id'])
    op.alter_column('cost_optimization_suggestions', 'user_id',
               existing_type=sa.VARCHAR(),
               type_=sa.Integer(),
               existing_nullable=True)
    op.create_foreign_key(None, 'cost_optimization_suggestions', 'user', ['user_id'], ['id'])
    op.alter_column('document_collections', 'name',
               existing_type=sa.VARCHAR(length=200),
               comment=None,
               existing_comment='Collection name',
               existing_nullable=False)
    op.alter_column('document_collections', 'description',
               existing_type=sa.TEXT(),
               type_=sqlmodel.sql.sqltypes.AutoString(),
               comment=None,
               existing_comment='Collection description',
               existing_nullable=True)
    op.alter_column('document_collections', 'source',
               existing_type=sa.VARCHAR(length=100),
               comment=None,
               existing_comment='Primary source authority',
               existing_nullable=False)
    op.alter_column('document_collections', 'document_type',
               existing_type=sa.VARCHAR(length=100),
               comment=None,
               existing_comment='Type of documents in collection',
               existing_nullable=False)
    op.alter_column('document_collections', 'document_count',
               existing_type=sa.INTEGER(),
               comment=None,
               existing_comment='Number of documents',
               existing_nullable=False)
    op.alter_column('document_collections', 'total_content_length',
               existing_type=sa.INTEGER(),
               comment=None,
               existing_comment='Total content length',
               existing_nullable=False)
    op.alter_column('document_collections', 'earliest_document',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               comment=None,
               existing_comment='Publication date of earliest document',
               existing_nullable=True)
    op.alter_column('document_collections', 'latest_document',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               comment=None,
               existing_comment='Publication date of latest document',
               existing_nullable=True)
    op.alter_column('document_collections', 'status',
               existing_type=sa.VARCHAR(length=20),
               comment=None,
               existing_comment='Collection status',
               existing_nullable=False)
    op.alter_column('document_collections', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               nullable=True,
               comment=None,
               existing_comment='Collection creation timestamp',
               existing_server_default=sa.text('now()'))
    op.alter_column('document_collections', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               nullable=True,
               comment=None,
               existing_comment='Last update timestamp',
               existing_server_default=sa.text('now()'))
    op.drop_index(op.f('idx_document_collections_created_at'), table_name='document_collections')
    op.drop_index(op.f('idx_document_collections_document_type'), table_name='document_collections')
    op.drop_index(op.f('idx_document_collections_source'), table_name='document_collections')
    op.drop_index(op.f('idx_document_collections_status'), table_name='document_collections')
    op.alter_column('document_processing_log', 'document_id',
               existing_type=sa.VARCHAR(length=100),
               comment=None,
               existing_comment='Associated regulatory document ID',
               existing_nullable=True)
    op.alter_column('document_processing_log', 'document_url',
               existing_type=sa.TEXT(),
               type_=sqlmodel.sql.sqltypes.AutoString(),
               comment=None,
               existing_comment='Document URL',
               existing_nullable=False)
    op.alter_column('document_processing_log', 'operation',
               existing_type=sa.VARCHAR(length=50),
               comment=None,
               existing_comment='Operation type (create, update, archive, etc.)',
               existing_nullable=False)
    op.alter_column('document_processing_log', 'status',
               existing_type=sa.VARCHAR(length=20),
               comment=None,
               existing_comment='Operation status (success, failed, partial)',
               existing_nullable=False)
    op.alter_column('document_processing_log', 'processing_time_ms',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               comment=None,
               existing_comment='Processing time in milliseconds',
               existing_nullable=True)
    op.alter_column('document_processing_log', 'content_length',
               existing_type=sa.INTEGER(),
               comment=None,
               existing_comment='Extracted content length',
               existing_nullable=True)
    op.alter_column('document_processing_log', 'error_message',
               existing_type=sa.TEXT(),
               type_=sqlmodel.sql.sqltypes.AutoString(),
               comment=None,
               existing_comment='Error message if operation failed',
               existing_nullable=True)
    op.alter_column('document_processing_log', 'error_details',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment=None,
               existing_comment='Detailed error information',
               existing_nullable=True)
    op.alter_column('document_processing_log', 'triggered_by',
               existing_type=sa.VARCHAR(length=50),
               comment=None,
               existing_comment='What triggered this operation (scheduler, manual, api)',
               existing_nullable=False)
    op.alter_column('document_processing_log', 'feed_url',
               existing_type=sa.TEXT(),
               type_=sqlmodel.sql.sqltypes.AutoString(),
               comment=None,
               existing_comment='Source RSS feed URL',
               existing_nullable=True)
    op.alter_column('document_processing_log', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               nullable=True,
               comment=None,
               existing_comment='Log entry timestamp',
               existing_server_default=sa.text('now()'))
    op.drop_index(op.f('idx_document_processing_log_created_at'), table_name='document_processing_log')
    op.drop_index(op.f('idx_document_processing_log_document_id'), table_name='document_processing_log')
    op.drop_index(op.f('idx_document_processing_log_operation'), table_name='document_processing_log')
    op.drop_index(op.f('idx_document_processing_log_status'), table_name='document_processing_log')
    op.drop_index(op.f('idx_document_processing_log_status_date'), table_name='document_processing_log')
    op.drop_index(op.f('idx_document_processing_log_triggered_by'), table_name='document_processing_log')
    op.create_foreign_key(None, 'document_processing_log', 'regulatory_documents', ['document_id'], ['id'])
    op.add_column('faq_entries', sa.Column('similarity_score', sa.Float(), nullable=True))
    op.alter_column('faq_entries', 'question',
               existing_type=sa.TEXT(),
               nullable=True)
    op.alter_column('faq_entries', 'answer',
               existing_type=sa.TEXT(),
               nullable=True)
    op.alter_column('faq_entries', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               nullable=True,
               existing_server_default=sa.text('now()'))
    op.alter_column('faq_entries', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               nullable=True,
               existing_server_default=sa.text('now()'))
    op.alter_column('faq_entries', 'search_vector',
               existing_type=sa.TEXT(),
               type_=sqlmodel.sql.sqltypes.AutoString(),
               existing_nullable=True)
    op.drop_index(op.f('idx_faq_entries_category'), table_name='faq_entries')
    op.drop_index(op.f('idx_faq_entries_category_needs_review'), table_name='faq_entries')
    op.drop_index(op.f('idx_faq_entries_created_at'), table_name='faq_entries')
    op.drop_index(op.f('idx_faq_entries_fts'), table_name='faq_entries', postgresql_using='gin')
    op.drop_index(op.f('idx_faq_entries_hit_count'), table_name='faq_entries')
    op.drop_index(op.f('idx_faq_entries_language'), table_name='faq_entries')
    op.drop_index(op.f('idx_faq_entries_language_category'), table_name='faq_entries')
    op.drop_index(op.f('idx_faq_entries_last_used'), table_name='faq_entries')
    op.drop_index(op.f('idx_faq_entries_needs_review'), table_name='faq_entries')
    op.drop_index(op.f('idx_faq_entries_question_embedding_ivfflat'), table_name='faq_entries', postgresql_with={'lists': '100'}, postgresql_using='ivfflat')
    op.drop_index(op.f('idx_faq_entries_update_sensitivity'), table_name='faq_entries')
    op.drop_index(op.f('idx_faq_entries_updated_at'), table_name='faq_entries')
    op.drop_column('faq_entries', 'question_embedding')
    op.alter_column('feed_status', 'feed_url',
               existing_type=sa.TEXT(),
               type_=sqlmodel.sql.sqltypes.AutoString(),
               comment=None,
               existing_comment='RSS feed URL',
               existing_nullable=False)
    op.alter_column('feed_status', 'source',
               existing_type=sa.VARCHAR(length=100),
               comment=None,
               existing_comment='Source authority',
               existing_nullable=True)
    op.alter_column('feed_status', 'feed_type',
               existing_type=sa.VARCHAR(length=100),
               comment=None,
               existing_comment='Type of feed',
               existing_nullable=True)
    op.alter_column('feed_status', 'parser',
               existing_type=sa.TEXT(),
               type_=sqlmodel.sql.sqltypes.AutoString(),
               existing_nullable=True)
    op.alter_column('feed_status', 'status',
               existing_type=sa.VARCHAR(length=20),
               comment=None,
               existing_comment='Current status (healthy, unhealthy, error)',
               existing_nullable=False)
    op.alter_column('feed_status', 'last_checked',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               nullable=True,
               comment=None,
               existing_comment='Last health check timestamp',
               existing_server_default=sa.text('now()'))
    op.alter_column('feed_status', 'last_success',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment=None,
               existing_comment='Last successful fetch timestamp',
               existing_nullable=True)
    op.alter_column('feed_status', 'response_time_ms',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               comment=None,
               existing_comment='Last response time in milliseconds',
               existing_nullable=True)
    op.alter_column('feed_status', 'items_found',
               existing_type=sa.INTEGER(),
               comment=None,
               existing_comment='Number of items in last successful fetch',
               existing_nullable=True)
    op.alter_column('feed_status', 'consecutive_errors',
               existing_type=sa.INTEGER(),
               comment=None,
               existing_comment='Count of consecutive errors',
               existing_nullable=False)
    op.alter_column('feed_status', 'errors',
               existing_type=sa.INTEGER(),
               comment=None,
               existing_comment='Total error count',
               existing_nullable=False)
    op.alter_column('feed_status', 'last_error',
               existing_type=sa.TEXT(),
               type_=sqlmodel.sql.sqltypes.AutoString(),
               comment=None,
               existing_comment='Last error message',
               existing_nullable=True)
    op.alter_column('feed_status', 'last_error_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment=None,
               existing_comment='Last error timestamp',
               existing_nullable=True)
    op.alter_column('feed_status', 'check_interval_minutes',
               existing_type=sa.INTEGER(),
               comment=None,
               existing_comment='Check interval in minutes',
               existing_nullable=False)
    op.alter_column('feed_status', 'enabled',
               existing_type=sa.BOOLEAN(),
               comment=None,
               existing_comment='Whether feed monitoring is enabled',
               existing_nullable=False)
    op.alter_column('feed_status', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               nullable=True,
               comment=None,
               existing_comment='Record creation timestamp',
               existing_server_default=sa.text('now()'))
    op.alter_column('feed_status', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               nullable=True,
               comment=None,
               existing_comment='Last update timestamp',
               existing_server_default=sa.text('now()'))
    op.drop_index(op.f('idx_feed_status_enabled'), table_name='feed_status')
    op.drop_index(op.f('idx_feed_status_errors'), table_name='feed_status')
    op.drop_index(op.f('idx_feed_status_last_checked'), table_name='feed_status')
    op.drop_index(op.f('idx_feed_status_parser'), table_name='feed_status')
    op.drop_index(op.f('idx_feed_status_source'), table_name='feed_status')
    op.drop_index(op.f('idx_feed_status_status'), table_name='feed_status')
    op.drop_index(op.f('idx_feed_status_url_unique'), table_name='feed_status')
    op.create_unique_constraint(None, 'feed_status', ['feed_url'])
    op.alter_column('knowledge_chunks', 'chunk_text',
               existing_type=sa.TEXT(),
               nullable=True)
    op.alter_column('knowledge_chunks', 'quality_score',
               existing_type=sa.NUMERIC(),
               type_=sa.Float(),
               existing_nullable=True)
    op.drop_index(op.f('idx_chunk_search_vector'), table_name='knowledge_chunks', postgresql_using='gin')
    op.drop_index(op.f('idx_kc_fts'), table_name='knowledge_chunks', postgresql_using='gin')
    op.drop_index(op.f('idx_kc_not_junk'), table_name='knowledge_chunks', postgresql_where='(junk = false)')
    op.drop_index(op.f('idx_kc_vec'), table_name='knowledge_chunks', postgresql_with={'lists': '100'}, postgresql_using='ivfflat')
    op.drop_index(op.f('idx_chunk_kb_epoch'), table_name='knowledge_chunks')
    op.create_index('idx_chunk_kb_epoch', 'knowledge_chunks', ['kb_epoch'], unique=False)
    op.drop_constraint(op.f('knowledge_chunks_knowledge_item_id_fkey'), 'knowledge_chunks', type_='foreignkey')
    op.create_foreign_key(None, 'knowledge_chunks', 'knowledge_items', ['knowledge_item_id'], ['id'])
    op.alter_column('knowledge_feedback', 'user_id',
               existing_type=sa.VARCHAR(),
               type_=sa.Integer(),
               existing_nullable=False)
    op.create_foreign_key(None, 'knowledge_feedback', 'user', ['user_id'], ['id'])
    op.alter_column('knowledge_items', 'last_accessed',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
    op.alter_column('knowledge_items', 'extraction_method',
               existing_type=sa.TEXT(),
               type_=sqlmodel.sql.sqltypes.AutoString(),
               existing_nullable=True)
    op.alter_column('knowledge_items', 'text_quality',
               existing_type=sa.NUMERIC(),
               type_=sa.Float(),
               existing_nullable=True)
    op.alter_column('knowledge_items', 'ocr_pages',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=True)
    op.alter_column('knowledge_items', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               nullable=True)
    op.alter_column('knowledge_items', 'updated_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               nullable=True)
    op.alter_column('knowledge_items', 'reviewed_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
    op.drop_index(op.f('idx_ki_extraction_method'), table_name='knowledge_items', postgresql_where='(extraction_method IS NOT NULL)')
    op.drop_index(op.f('idx_ki_fts'), table_name='knowledge_items', postgresql_using='gin')
    op.drop_index(op.f('idx_ki_publication_date'), table_name='knowledge_items', postgresql_where='(publication_date IS NOT NULL)')
    op.drop_index(op.f('idx_ki_text_quality'), table_name='knowledge_items', postgresql_where='(text_quality IS NOT NULL)')
    op.drop_index(op.f('idx_ki_vec'), table_name='knowledge_items', postgresql_with={'lists': '50'}, postgresql_using='ivfflat')
    op.drop_index(op.f('idx_knowledge_items_kb_epoch'), table_name='knowledge_items')
    op.alter_column('regulatory_documents', 'source',
               existing_type=sa.VARCHAR(length=100),
               comment=None,
               existing_comment='Source authority (agenzia_entrate, inps, etc.)',
               existing_nullable=False)
    op.alter_column('regulatory_documents', 'source_type',
               existing_type=sa.VARCHAR(length=100),
               comment=None,
               existing_comment='Document type (circolari, risoluzioni, etc.)',
               existing_nullable=False)
    op.alter_column('regulatory_documents', 'title',
               existing_type=sa.TEXT(),
               type_=sqlmodel.sql.sqltypes.AutoString(),
               comment=None,
               existing_comment='Document title',
               existing_nullable=False)
    op.alter_column('regulatory_documents', 'url',
               existing_type=sa.TEXT(),
               type_=sqlmodel.sql.sqltypes.AutoString(),
               comment=None,
               existing_comment='Original document URL',
               existing_nullable=False)
    op.alter_column('regulatory_documents', 'published_date',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               comment=None,
               existing_comment='Official publication date',
               existing_nullable=True)
    op.alter_column('regulatory_documents', 'content',
               existing_type=sa.TEXT(),
               nullable=True,
               comment=None,
               existing_comment='Extracted text content')
    op.alter_column('regulatory_documents', 'content_hash',
               existing_type=sa.VARCHAR(length=64),
               comment=None,
               existing_comment='SHA256 hash for duplicate detection',
               existing_nullable=False)
    op.alter_column('regulatory_documents', 'document_number',
               existing_type=sa.VARCHAR(length=50),
               comment=None,
               existing_comment='Official document number',
               existing_nullable=True)
    op.alter_column('regulatory_documents', 'authority',
               existing_type=sa.VARCHAR(length=200),
               comment=None,
               existing_comment='Publishing authority name',
               existing_nullable=True)
    op.alter_column('regulatory_documents', 'document_metadata',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment=None,
               existing_comment='Additional document metadata',
               existing_nullable=True)
    op.alter_column('regulatory_documents', 'version',
               existing_type=sa.INTEGER(),
               comment=None,
               existing_comment='Document version number',
               existing_nullable=False)
    op.alter_column('regulatory_documents', 'previous_version_id',
               existing_type=sa.VARCHAR(length=100),
               comment=None,
               existing_comment='ID of previous version if this is an update',
               existing_nullable=True)
    op.alter_column('regulatory_documents', 'status',
               existing_type=sa.VARCHAR(length=20),
               type_=sa.Enum('PENDING', 'PROCESSING', 'PROCESSED', 'FAILED', 'ACTIVE', 'SUPERSEDED', 'ARCHIVED', name='processingstatus'),
               comment=None,
               existing_comment='Current processing status',
               existing_nullable=False)
    op.alter_column('regulatory_documents', 'processed_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               comment=None,
               existing_comment='When document was successfully processed',
               existing_nullable=True)
    op.alter_column('regulatory_documents', 'processing_errors',
               existing_type=sa.TEXT(),
               type_=sqlmodel.sql.sqltypes.AutoString(),
               comment=None,
               existing_comment='Any errors encountered during processing',
               existing_nullable=True)
    op.alter_column('regulatory_documents', 'knowledge_item_id',
               existing_type=sa.INTEGER(),
               comment=None,
               existing_comment='Associated knowledge_items record ID',
               existing_nullable=True)
    op.alter_column('regulatory_documents', 'topics',
               existing_type=sa.TEXT(),
               type_=sqlmodel.sql.sqltypes.AutoString(),
               comment=None,
               existing_comment='Comma-separated list of topics/keywords',
               existing_nullable=True)
    op.alter_column('regulatory_documents', 'importance_score',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               comment=None,
               existing_comment='Calculated importance score (0.0-1.0)',
               existing_nullable=False)
    op.alter_column('regulatory_documents', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               nullable=True,
               comment=None,
               existing_comment='Record creation timestamp',
               existing_server_default=sa.text('now()'))
    op.alter_column('regulatory_documents', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               nullable=True,
               comment=None,
               existing_comment='Last update timestamp',
               existing_server_default=sa.text('now()'))
    op.alter_column('regulatory_documents', 'archived_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               comment=None,
               existing_comment='When document was archived',
               existing_nullable=True)
    op.alter_column('regulatory_documents', 'archive_reason',
               existing_type=sa.TEXT(),
               type_=sqlmodel.sql.sqltypes.AutoString(),
               comment=None,
               existing_comment='Reason for archiving',
               existing_nullable=True)
    op.drop_index(op.f('idx_regulatory_documents_content_hash'), table_name='regulatory_documents')
    op.drop_index(op.f('idx_regulatory_documents_created_at'), table_name='regulatory_documents')
    op.drop_index(op.f('idx_regulatory_documents_published_date'), table_name='regulatory_documents')
    op.drop_index(op.f('idx_regulatory_documents_source'), table_name='regulatory_documents')
    op.drop_index(op.f('idx_regulatory_documents_source_status'), table_name='regulatory_documents')
    op.drop_index(op.f('idx_regulatory_documents_source_type'), table_name='regulatory_documents')
    op.drop_index(op.f('idx_regulatory_documents_status'), table_name='regulatory_documents')
    op.drop_index(op.f('idx_regulatory_documents_status_published'), table_name='regulatory_documents')
    op.drop_index(op.f('idx_regulatory_documents_updated_at'), table_name='regulatory_documents')
    op.drop_index(op.f('idx_regulatory_documents_url'), table_name='regulatory_documents')
    op.drop_index(op.f('idx_regulatory_documents_url_unique'), table_name='regulatory_documents')
    op.create_unique_constraint(None, 'regulatory_documents', ['url'])
    op.alter_column('usage_events', 'user_id',
               existing_type=sa.VARCHAR(),
               type_=sa.Integer(),
               existing_nullable=False)
    op.create_foreign_key(None, 'usage_events', 'user', ['user_id'], ['id'])
    op.alter_column('usage_quotas', 'user_id',
               existing_type=sa.VARCHAR(),
               type_=sa.Integer(),
               existing_nullable=False)
    op.create_foreign_key(None, 'usage_quotas', 'user', ['user_id'], ['id'])
    op.alter_column('user', 'name',
               existing_type=sa.VARCHAR(length=255),
               comment=None,
               existing_comment='User full name from OAuth provider or manual registration',
               existing_nullable=True)
    op.alter_column('user', 'avatar_url',
               existing_type=sa.VARCHAR(length=512),
               comment=None,
               existing_comment='URL to user profile picture from OAuth provider',
               existing_nullable=True)
    op.alter_column('user', 'provider',
               existing_type=sa.VARCHAR(length=50),
               comment=None,
               existing_comment='Authentication provider: email, google, linkedin',
               existing_nullable=False,
               existing_server_default=sa.text("'email'::character varying"))
    op.alter_column('user', 'provider_id',
               existing_type=sa.VARCHAR(length=255),
               comment=None,
               existing_comment='Unique user ID from OAuth provider',
               existing_nullable=True)
    op.drop_index(op.f('ix_user_role'), table_name='user')
    op.drop_constraint(op.f('uq_user_provider_provider_id'), 'user', type_='unique')
    op.create_index(op.f('ix_user_refresh_token_hash'), 'user', ['refresh_token_hash'], unique=False)
    op.drop_column('user', 'role')
    op.alter_column('user_usage_summaries', 'user_id',
               existing_type=sa.VARCHAR(),
               type_=sa.Integer(),
               existing_nullable=False)
    op.create_foreign_key(None, 'user_usage_summaries', 'user', ['user_id'], ['id'])
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_constraint(None, 'user_usage_summaries', type_='foreignkey')
    op.alter_column('user_usage_summaries', 'user_id',
               existing_type=sa.Integer(),
               type_=sa.VARCHAR(),
               existing_nullable=False)
    op.add_column('user', sa.Column('role', sa.VARCHAR(length=20), server_default=sa.text("'user'::character varying"), autoincrement=False, nullable=False))
    op.drop_index(op.f('ix_user_refresh_token_hash'), table_name='user')
    op.create_unique_constraint(op.f('uq_user_provider_provider_id'), 'user', ['provider', 'provider_id'])
    op.create_index(op.f('ix_user_role'), 'user', ['role'], unique=False)
    op.alter_column('user', 'provider_id',
               existing_type=sa.VARCHAR(length=255),
               comment='Unique user ID from OAuth provider',
               existing_nullable=True)
    op.alter_column('user', 'provider',
               existing_type=sa.VARCHAR(length=50),
               comment='Authentication provider: email, google, linkedin',
               existing_nullable=False,
               existing_server_default=sa.text("'email'::character varying"))
    op.alter_column('user', 'avatar_url',
               existing_type=sa.VARCHAR(length=512),
               comment='URL to user profile picture from OAuth provider',
               existing_nullable=True)
    op.alter_column('user', 'name',
               existing_type=sa.VARCHAR(length=255),
               comment='User full name from OAuth provider or manual registration',
               existing_nullable=True)
    op.drop_constraint(None, 'usage_quotas', type_='foreignkey')
    op.alter_column('usage_quotas', 'user_id',
               existing_type=sa.Integer(),
               type_=sa.VARCHAR(),
               existing_nullable=False)
    op.drop_constraint(None, 'usage_events', type_='foreignkey')
    op.alter_column('usage_events', 'user_id',
               existing_type=sa.Integer(),
               type_=sa.VARCHAR(),
               existing_nullable=False)
    op.drop_constraint(None, 'regulatory_documents', type_='unique')
    op.create_index(op.f('idx_regulatory_documents_url_unique'), 'regulatory_documents', ['url'], unique=True)
    op.create_index(op.f('idx_regulatory_documents_url'), 'regulatory_documents', ['url'], unique=False)
    op.create_index(op.f('idx_regulatory_documents_updated_at'), 'regulatory_documents', ['updated_at'], unique=False)
    op.create_index(op.f('idx_regulatory_documents_status_published'), 'regulatory_documents', ['status', 'published_date'], unique=False)
    op.create_index(op.f('idx_regulatory_documents_status'), 'regulatory_documents', ['status'], unique=False)
    op.create_index(op.f('idx_regulatory_documents_source_type'), 'regulatory_documents', ['source_type'], unique=False)
    op.create_index(op.f('idx_regulatory_documents_source_status'), 'regulatory_documents', ['source', 'status'], unique=False)
    op.create_index(op.f('idx_regulatory_documents_source'), 'regulatory_documents', ['source'], unique=False)
    op.create_index(op.f('idx_regulatory_documents_published_date'), 'regulatory_documents', ['published_date'], unique=False)
    op.create_index(op.f('idx_regulatory_documents_created_at'), 'regulatory_documents', ['created_at'], unique=False)
    op.create_index(op.f('idx_regulatory_documents_content_hash'), 'regulatory_documents', ['content_hash'], unique=False)
    op.alter_column('regulatory_documents', 'archive_reason',
               existing_type=sqlmodel.sql.sqltypes.AutoString(),
               type_=sa.TEXT(),
               comment='Reason for archiving',
               existing_nullable=True)
    op.alter_column('regulatory_documents', 'archived_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               comment='When document was archived',
               existing_nullable=True)
    op.alter_column('regulatory_documents', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               nullable=False,
               comment='Last update timestamp',
               existing_server_default=sa.text('now()'))
    op.alter_column('regulatory_documents', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               nullable=False,
               comment='Record creation timestamp',
               existing_server_default=sa.text('now()'))
    op.alter_column('regulatory_documents', 'importance_score',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               comment='Calculated importance score (0.0-1.0)',
               existing_nullable=False)
    op.alter_column('regulatory_documents', 'topics',
               existing_type=sqlmodel.sql.sqltypes.AutoString(),
               type_=sa.TEXT(),
               comment='Comma-separated list of topics/keywords',
               existing_nullable=True)
    op.alter_column('regulatory_documents', 'knowledge_item_id',
               existing_type=sa.INTEGER(),
               comment='Associated knowledge_items record ID',
               existing_nullable=True)
    op.alter_column('regulatory_documents', 'processing_errors',
               existing_type=sqlmodel.sql.sqltypes.AutoString(),
               type_=sa.TEXT(),
               comment='Any errors encountered during processing',
               existing_nullable=True)
    op.alter_column('regulatory_documents', 'processed_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               comment='When document was successfully processed',
               existing_nullable=True)
    op.alter_column('regulatory_documents', 'status',
               existing_type=sa.Enum('PENDING', 'PROCESSING', 'PROCESSED', 'FAILED', 'ACTIVE', 'SUPERSEDED', 'ARCHIVED', name='processingstatus'),
               type_=sa.VARCHAR(length=20),
               comment='Current processing status',
               existing_nullable=False)
    op.alter_column('regulatory_documents', 'previous_version_id',
               existing_type=sa.VARCHAR(length=100),
               comment='ID of previous version if this is an update',
               existing_nullable=True)
    op.alter_column('regulatory_documents', 'version',
               existing_type=sa.INTEGER(),
               comment='Document version number',
               existing_nullable=False)
    op.alter_column('regulatory_documents', 'document_metadata',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment='Additional document metadata',
               existing_nullable=True)
    op.alter_column('regulatory_documents', 'authority',
               existing_type=sa.VARCHAR(length=200),
               comment='Publishing authority name',
               existing_nullable=True)
    op.alter_column('regulatory_documents', 'document_number',
               existing_type=sa.VARCHAR(length=50),
               comment='Official document number',
               existing_nullable=True)
    op.alter_column('regulatory_documents', 'content_hash',
               existing_type=sa.VARCHAR(length=64),
               comment='SHA256 hash for duplicate detection',
               existing_nullable=False)
    op.alter_column('regulatory_documents', 'content',
               existing_type=sa.TEXT(),
               nullable=False,
               comment='Extracted text content')
    op.alter_column('regulatory_documents', 'published_date',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               comment='Official publication date',
               existing_nullable=True)
    op.alter_column('regulatory_documents', 'url',
               existing_type=sqlmodel.sql.sqltypes.AutoString(),
               type_=sa.TEXT(),
               comment='Original document URL',
               existing_nullable=False)
    op.alter_column('regulatory_documents', 'title',
               existing_type=sqlmodel.sql.sqltypes.AutoString(),
               type_=sa.TEXT(),
               comment='Document title',
               existing_nullable=False)
    op.alter_column('regulatory_documents', 'source_type',
               existing_type=sa.VARCHAR(length=100),
               comment='Document type (circolari, risoluzioni, etc.)',
               existing_nullable=False)
    op.alter_column('regulatory_documents', 'source',
               existing_type=sa.VARCHAR(length=100),
               comment='Source authority (agenzia_entrate, inps, etc.)',
               existing_nullable=False)
    op.create_index(op.f('idx_knowledge_items_kb_epoch'), 'knowledge_items', [sa.literal_column('kb_epoch DESC')], unique=False)
    op.create_index(op.f('idx_ki_vec'), 'knowledge_items', ['embedding'], unique=False, postgresql_with={'lists': '50'}, postgresql_using='ivfflat')
    op.create_index(op.f('idx_ki_text_quality'), 'knowledge_items', ['text_quality'], unique=False, postgresql_where='(text_quality IS NOT NULL)')
    op.create_index(op.f('idx_ki_publication_date'), 'knowledge_items', ['publication_date'], unique=False, postgresql_where='(publication_date IS NOT NULL)')
    op.create_index(op.f('idx_ki_fts'), 'knowledge_items', ['search_vector'], unique=False, postgresql_using='gin')
    op.create_index(op.f('idx_ki_extraction_method'), 'knowledge_items', ['extraction_method'], unique=False, postgresql_where='(extraction_method IS NOT NULL)')
    op.alter_column('knowledge_items', 'reviewed_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)
    op.alter_column('knowledge_items', 'updated_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               nullable=False)
    op.alter_column('knowledge_items', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               nullable=False)
    op.alter_column('knowledge_items', 'ocr_pages',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True)
    op.alter_column('knowledge_items', 'text_quality',
               existing_type=sa.Float(),
               type_=sa.NUMERIC(),
               existing_nullable=True)
    op.alter_column('knowledge_items', 'extraction_method',
               existing_type=sqlmodel.sql.sqltypes.AutoString(),
               type_=sa.TEXT(),
               existing_nullable=True)
    op.alter_column('knowledge_items', 'last_accessed',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)
    op.drop_constraint(None, 'knowledge_feedback', type_='foreignkey')
    op.alter_column('knowledge_feedback', 'user_id',
               existing_type=sa.Integer(),
               type_=sa.VARCHAR(),
               existing_nullable=False)
    op.drop_constraint(None, 'knowledge_chunks', type_='foreignkey')
    op.create_foreign_key(op.f('knowledge_chunks_knowledge_item_id_fkey'), 'knowledge_chunks', 'knowledge_items', ['knowledge_item_id'], ['id'], ondelete='CASCADE')
    op.drop_index('idx_chunk_kb_epoch', table_name='knowledge_chunks')
    op.create_index(op.f('idx_chunk_kb_epoch'), 'knowledge_chunks', [sa.literal_column('kb_epoch DESC')], unique=False)
    op.create_index(op.f('idx_kc_vec'), 'knowledge_chunks', ['embedding'], unique=False, postgresql_with={'lists': '100'}, postgresql_using='ivfflat')
    op.create_index(op.f('idx_kc_not_junk'), 'knowledge_chunks', ['knowledge_item_id'], unique=False, postgresql_where='(junk = false)')
    op.create_index(op.f('idx_kc_fts'), 'knowledge_chunks', ['search_vector'], unique=False, postgresql_using='gin')
    op.create_index(op.f('idx_chunk_search_vector'), 'knowledge_chunks', ['search_vector'], unique=False, postgresql_using='gin')
    op.alter_column('knowledge_chunks', 'quality_score',
               existing_type=sa.Float(),
               type_=sa.NUMERIC(),
               existing_nullable=True)
    op.alter_column('knowledge_chunks', 'chunk_text',
               existing_type=sa.TEXT(),
               nullable=False)
    op.drop_constraint(None, 'feed_status', type_='unique')
    op.create_index(op.f('idx_feed_status_url_unique'), 'feed_status', ['feed_url'], unique=True)
    op.create_index(op.f('idx_feed_status_status'), 'feed_status', ['status'], unique=False)
    op.create_index(op.f('idx_feed_status_source'), 'feed_status', ['source'], unique=False)
    op.create_index(op.f('idx_feed_status_parser'), 'feed_status', ['parser'], unique=False)
    op.create_index(op.f('idx_feed_status_last_checked'), 'feed_status', ['last_checked'], unique=False)
    op.create_index(op.f('idx_feed_status_errors'), 'feed_status', ['consecutive_errors'], unique=False)
    op.create_index(op.f('idx_feed_status_enabled'), 'feed_status', ['enabled'], unique=False)
    op.alter_column('feed_status', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               nullable=False,
               comment='Last update timestamp',
               existing_server_default=sa.text('now()'))
    op.alter_column('feed_status', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               nullable=False,
               comment='Record creation timestamp',
               existing_server_default=sa.text('now()'))
    op.alter_column('feed_status', 'enabled',
               existing_type=sa.BOOLEAN(),
               comment='Whether feed monitoring is enabled',
               existing_nullable=False)
    op.alter_column('feed_status', 'check_interval_minutes',
               existing_type=sa.INTEGER(),
               comment='Check interval in minutes',
               existing_nullable=False)
    op.alter_column('feed_status', 'last_error_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment='Last error timestamp',
               existing_nullable=True)
    op.alter_column('feed_status', 'last_error',
               existing_type=sqlmodel.sql.sqltypes.AutoString(),
               type_=sa.TEXT(),
               comment='Last error message',
               existing_nullable=True)
    op.alter_column('feed_status', 'errors',
               existing_type=sa.INTEGER(),
               comment='Total error count',
               existing_nullable=False)
    op.alter_column('feed_status', 'consecutive_errors',
               existing_type=sa.INTEGER(),
               comment='Count of consecutive errors',
               existing_nullable=False)
    op.alter_column('feed_status', 'items_found',
               existing_type=sa.INTEGER(),
               comment='Number of items in last successful fetch',
               existing_nullable=True)
    op.alter_column('feed_status', 'response_time_ms',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               comment='Last response time in milliseconds',
               existing_nullable=True)
    op.alter_column('feed_status', 'last_success',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment='Last successful fetch timestamp',
               existing_nullable=True)
    op.alter_column('feed_status', 'last_checked',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               nullable=False,
               comment='Last health check timestamp',
               existing_server_default=sa.text('now()'))
    op.alter_column('feed_status', 'status',
               existing_type=sa.VARCHAR(length=20),
               comment='Current status (healthy, unhealthy, error)',
               existing_nullable=False)
    op.alter_column('feed_status', 'parser',
               existing_type=sqlmodel.sql.sqltypes.AutoString(),
               type_=sa.TEXT(),
               existing_nullable=True)
    op.alter_column('feed_status', 'feed_type',
               existing_type=sa.VARCHAR(length=100),
               comment='Type of feed',
               existing_nullable=True)
    op.alter_column('feed_status', 'source',
               existing_type=sa.VARCHAR(length=100),
               comment='Source authority',
               existing_nullable=True)
    op.alter_column('feed_status', 'feed_url',
               existing_type=sqlmodel.sql.sqltypes.AutoString(),
               type_=sa.TEXT(),
               comment='RSS feed URL',
               existing_nullable=False)
    op.add_column('faq_entries', sa.Column('question_embedding', pgvector.sqlalchemy.vector.VECTOR(dim=1536), autoincrement=False, nullable=True))
    op.create_index(op.f('idx_faq_entries_updated_at'), 'faq_entries', ['updated_at'], unique=False)
    op.create_index(op.f('idx_faq_entries_update_sensitivity'), 'faq_entries', ['update_sensitivity'], unique=False)
    op.create_index(op.f('idx_faq_entries_question_embedding_ivfflat'), 'faq_entries', ['question_embedding'], unique=False, postgresql_with={'lists': '100'}, postgresql_using='ivfflat')
    op.create_index(op.f('idx_faq_entries_needs_review'), 'faq_entries', ['needs_review'], unique=False)
    op.create_index(op.f('idx_faq_entries_last_used'), 'faq_entries', ['last_used'], unique=False)
    op.create_index(op.f('idx_faq_entries_language_category'), 'faq_entries', ['language', 'category'], unique=False)
    op.create_index(op.f('idx_faq_entries_language'), 'faq_entries', ['language'], unique=False)
    op.create_index(op.f('idx_faq_entries_hit_count'), 'faq_entries', ['hit_count'], unique=False)
    op.create_index(op.f('idx_faq_entries_fts'), 'faq_entries', [sa.literal_column("to_tsvector('italian'::regconfig, (question || ' '::text) || answer)")], unique=False, postgresql_using='gin')
    op.create_index(op.f('idx_faq_entries_created_at'), 'faq_entries', ['created_at'], unique=False)
    op.create_index(op.f('idx_faq_entries_category_needs_review'), 'faq_entries', ['category', 'needs_review'], unique=False)
    op.create_index(op.f('idx_faq_entries_category'), 'faq_entries', ['category'], unique=False)
    op.alter_column('faq_entries', 'search_vector',
               existing_type=sqlmodel.sql.sqltypes.AutoString(),
               type_=sa.TEXT(),
               existing_nullable=True)
    op.alter_column('faq_entries', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               nullable=False,
               existing_server_default=sa.text('now()'))
    op.alter_column('faq_entries', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               nullable=False,
               existing_server_default=sa.text('now()'))
    op.alter_column('faq_entries', 'answer',
               existing_type=sa.TEXT(),
               nullable=False)
    op.alter_column('faq_entries', 'question',
               existing_type=sa.TEXT(),
               nullable=False)
    op.drop_column('faq_entries', 'similarity_score')
    op.drop_constraint(None, 'document_processing_log', type_='foreignkey')
    op.create_index(op.f('idx_document_processing_log_triggered_by'), 'document_processing_log', ['triggered_by'], unique=False)
    op.create_index(op.f('idx_document_processing_log_status_date'), 'document_processing_log', ['status', 'created_at'], unique=False)
    op.create_index(op.f('idx_document_processing_log_status'), 'document_processing_log', ['status'], unique=False)
    op.create_index(op.f('idx_document_processing_log_operation'), 'document_processing_log', ['operation'], unique=False)
    op.create_index(op.f('idx_document_processing_log_document_id'), 'document_processing_log', ['document_id'], unique=False)
    op.create_index(op.f('idx_document_processing_log_created_at'), 'document_processing_log', ['created_at'], unique=False)
    op.alter_column('document_processing_log', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               nullable=False,
               comment='Log entry timestamp',
               existing_server_default=sa.text('now()'))
    op.alter_column('document_processing_log', 'feed_url',
               existing_type=sqlmodel.sql.sqltypes.AutoString(),
               type_=sa.TEXT(),
               comment='Source RSS feed URL',
               existing_nullable=True)
    op.alter_column('document_processing_log', 'triggered_by',
               existing_type=sa.VARCHAR(length=50),
               comment='What triggered this operation (scheduler, manual, api)',
               existing_nullable=False)
    op.alter_column('document_processing_log', 'error_details',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment='Detailed error information',
               existing_nullable=True)
    op.alter_column('document_processing_log', 'error_message',
               existing_type=sqlmodel.sql.sqltypes.AutoString(),
               type_=sa.TEXT(),
               comment='Error message if operation failed',
               existing_nullable=True)
    op.alter_column('document_processing_log', 'content_length',
               existing_type=sa.INTEGER(),
               comment='Extracted content length',
               existing_nullable=True)
    op.alter_column('document_processing_log', 'processing_time_ms',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               comment='Processing time in milliseconds',
               existing_nullable=True)
    op.alter_column('document_processing_log', 'status',
               existing_type=sa.VARCHAR(length=20),
               comment='Operation status (success, failed, partial)',
               existing_nullable=False)
    op.alter_column('document_processing_log', 'operation',
               existing_type=sa.VARCHAR(length=50),
               comment='Operation type (create, update, archive, etc.)',
               existing_nullable=False)
    op.alter_column('document_processing_log', 'document_url',
               existing_type=sqlmodel.sql.sqltypes.AutoString(),
               type_=sa.TEXT(),
               comment='Document URL',
               existing_nullable=False)
    op.alter_column('document_processing_log', 'document_id',
               existing_type=sa.VARCHAR(length=100),
               comment='Associated regulatory document ID',
               existing_nullable=True)
    op.create_index(op.f('idx_document_collections_status'), 'document_collections', ['status'], unique=False)
    op.create_index(op.f('idx_document_collections_source'), 'document_collections', ['source'], unique=False)
    op.create_index(op.f('idx_document_collections_document_type'), 'document_collections', ['document_type'], unique=False)
    op.create_index(op.f('idx_document_collections_created_at'), 'document_collections', ['created_at'], unique=False)
    op.alter_column('document_collections', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               nullable=False,
               comment='Last update timestamp',
               existing_server_default=sa.text('now()'))
    op.alter_column('document_collections', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               nullable=False,
               comment='Collection creation timestamp',
               existing_server_default=sa.text('now()'))
    op.alter_column('document_collections', 'status',
               existing_type=sa.VARCHAR(length=20),
               comment='Collection status',
               existing_nullable=False)
    op.alter_column('document_collections', 'latest_document',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               comment='Publication date of latest document',
               existing_nullable=True)
    op.alter_column('document_collections', 'earliest_document',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               comment='Publication date of earliest document',
               existing_nullable=True)
    op.alter_column('document_collections', 'total_content_length',
               existing_type=sa.INTEGER(),
               comment='Total content length',
               existing_nullable=False)
    op.alter_column('document_collections', 'document_count',
               existing_type=sa.INTEGER(),
               comment='Number of documents',
               existing_nullable=False)
    op.alter_column('document_collections', 'document_type',
               existing_type=sa.VARCHAR(length=100),
               comment='Type of documents in collection',
               existing_nullable=False)
    op.alter_column('document_collections', 'source',
               existing_type=sa.VARCHAR(length=100),
               comment='Primary source authority',
               existing_nullable=False)
    op.alter_column('document_collections', 'description',
               existing_type=sqlmodel.sql.sqltypes.AutoString(),
               type_=sa.TEXT(),
               comment='Collection description',
               existing_nullable=True)
    op.alter_column('document_collections', 'name',
               existing_type=sa.VARCHAR(length=200),
               comment='Collection name',
               existing_nullable=False)
    op.drop_constraint(None, 'cost_optimization_suggestions', type_='foreignkey')
    op.alter_column('cost_optimization_suggestions', 'user_id',
               existing_type=sa.Integer(),
               type_=sa.VARCHAR(),
               existing_nullable=True)
    op.drop_constraint(None, 'cost_alerts', type_='foreignkey')
    op.alter_column('cost_alerts', 'user_id',
               existing_type=sa.Integer(),
               type_=sa.VARCHAR(),
               existing_nullable=True)
    op.create_table('expert_generated_tasks',
    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), autoincrement=False, nullable=False),
    sa.Column('task_id', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('task_name', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('feedback_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('expert_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('question', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('answer', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('additional_details', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('file_path', sa.VARCHAR(length=200), server_default=sa.text("'SUPER_USER_TASKS.md'::character varying"), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['expert_id'], ['expert_profiles.id'], name=op.f('expert_generated_tasks_expert_id_fkey')),
    sa.ForeignKeyConstraint(['feedback_id'], ['expert_feedback.id'], name=op.f('expert_generated_tasks_feedback_id_fkey'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('expert_generated_tasks_pkey')),
    sa.UniqueConstraint('task_id', name=op.f('expert_generated_tasks_task_id_key'))
    )
    op.create_index(op.f('idx_egt_task_id'), 'expert_generated_tasks', ['task_id'], unique=False)
    op.create_index(op.f('idx_egt_feedback_id'), 'expert_generated_tasks', ['feedback_id'], unique=False)
    op.create_index(op.f('idx_egt_expert_id'), 'expert_generated_tasks', ['expert_id'], unique=False)
    op.create_index(op.f('idx_egt_created_at'), 'expert_generated_tasks', [sa.literal_column('created_at DESC')], unique=False)
    op.create_table('expert_profiles',
    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), autoincrement=False, nullable=False),
    sa.Column('user_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('credentials', postgresql.ARRAY(sa.TEXT()), server_default=sa.text("'{}'::text[]"), autoincrement=False, nullable=True),
    sa.Column('credential_types', postgresql.ARRAY(postgresql.ENUM('dottore_commercialista', 'revisore_legale', 'consulente_fiscale', 'consulente_lavoro', 'caf_operator', 'admin', name='expert_credential_type')), server_default=sa.text("'{}'::expert_credential_type[]"), autoincrement=False, nullable=True),
    sa.Column('experience_years', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=True),
    sa.Column('specializations', postgresql.ARRAY(sa.TEXT()), server_default=sa.text("'{}'::text[]"), autoincrement=False, nullable=True),
    sa.Column('feedback_count', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=True),
    sa.Column('feedback_accuracy_rate', sa.DOUBLE_PRECISION(precision=53), server_default=sa.text('0.0'), autoincrement=False, nullable=True),
    sa.Column('average_response_time_seconds', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=True),
    sa.Column('trust_score', sa.DOUBLE_PRECISION(precision=53), server_default=sa.text('0.5'), autoincrement=False, nullable=True),
    sa.Column('professional_registration_number', sa.VARCHAR(length=50), autoincrement=False, nullable=True),
    sa.Column('organization', sa.VARCHAR(length=200), autoincrement=False, nullable=True),
    sa.Column('location_city', sa.VARCHAR(length=100), autoincrement=False, nullable=True),
    sa.Column('is_verified', sa.BOOLEAN(), server_default=sa.text('false'), autoincrement=False, nullable=True),
    sa.Column('verification_date', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('is_active', sa.BOOLEAN(), server_default=sa.text('true'), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.CheckConstraint('experience_years >= 0', name='non_negative_experience'),
    sa.CheckConstraint('feedback_accuracy_rate >= 0.0::double precision AND feedback_accuracy_rate <= 1.0::double precision', name='accuracy_rate_range'),
    sa.CheckConstraint('feedback_count >= 0', name='non_negative_feedback_count'),
    sa.CheckConstraint('trust_score >= 0.0::double precision AND trust_score <= 1.0::double precision', name='trust_score_range'),
    sa.ForeignKeyConstraint(['user_id'], ['user.id'], name='expert_profiles_user_id_fkey', ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name='expert_profiles_pkey'),
    sa.UniqueConstraint('user_id', name='expert_profiles_user_id_key'),
    postgresql_ignore_search_path=False
    )
    op.create_index(op.f('idx_expert_profiles_trust_score'), 'expert_profiles', ['trust_score'], unique=False)
    op.create_index(op.f('idx_expert_profiles_specializations'), 'expert_profiles', ['specializations'], unique=False, postgresql_using='gin')
    op.create_index(op.f('idx_expert_profiles_active'), 'expert_profiles', ['is_active', 'is_verified'], unique=False)
    op.create_table('checkpoint_blobs',
    sa.Column('thread_id', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('checkpoint_ns', sa.TEXT(), server_default=sa.text("''::text"), autoincrement=False, nullable=False),
    sa.Column('channel', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('version', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('type', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('blob', postgresql.BYTEA(), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('thread_id', 'checkpoint_ns', 'channel', 'version', name=op.f('checkpoint_blobs_pkey'))
    )
    op.create_index(op.f('checkpoint_blobs_thread_id_idx'), 'checkpoint_blobs', ['thread_id'], unique=False)
    op.create_table('checkpoint_writes',
    sa.Column('thread_id', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('checkpoint_ns', sa.TEXT(), server_default=sa.text("''::text"), autoincrement=False, nullable=False),
    sa.Column('checkpoint_id', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('task_id', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('idx', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('channel', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('type', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('blob', postgresql.BYTEA(), autoincrement=False, nullable=False),
    sa.Column('task_path', sa.TEXT(), server_default=sa.text("''::text"), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('thread_id', 'checkpoint_ns', 'checkpoint_id', 'task_id', 'idx', name=op.f('checkpoint_writes_pkey'))
    )
    op.create_index(op.f('checkpoint_writes_thread_id_idx'), 'checkpoint_writes', ['thread_id'], unique=False)
    op.create_table('expert_faq_candidates',
    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), autoincrement=False, nullable=False),
    sa.Column('question', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('answer', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('source', sa.VARCHAR(length=20), server_default=sa.text("'expert_feedback'::character varying"), autoincrement=False, nullable=False),
    sa.Column('expert_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('expert_trust_score', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('approval_status', sa.VARCHAR(length=20), server_default=sa.text("'pending'::character varying"), autoincrement=False, nullable=True),
    sa.Column('approved_by', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('approved_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('suggested_category', sa.VARCHAR(length=100), autoincrement=False, nullable=True),
    sa.Column('suggested_tags', postgresql.ARRAY(sa.TEXT()), server_default=sa.text("'{}'::text[]"), autoincrement=False, nullable=True),
    sa.Column('regulatory_references', postgresql.ARRAY(sa.TEXT()), server_default=sa.text("'{}'::text[]"), autoincrement=False, nullable=True),
    sa.Column('frequency', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=True),
    sa.Column('estimated_monthly_savings', sa.NUMERIC(precision=10, scale=2), server_default=sa.text('0'), autoincrement=False, nullable=True),
    sa.Column('roi_score', sa.NUMERIC(precision=10, scale=2), server_default=sa.text('0'), autoincrement=False, nullable=True),
    sa.Column('priority_score', sa.NUMERIC(precision=10, scale=2), server_default=sa.text('0'), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('question_embedding', pgvector.sqlalchemy.vector.VECTOR(dim=1536), autoincrement=False, nullable=True, comment='Vector embedding of the FAQ question for semantic similarity search (OpenAI ada-002, 1536 dimensions)'),
    sa.CheckConstraint("approval_status::text = ANY (ARRAY['pending'::character varying, 'approved'::character varying, 'rejected'::character varying]::text[])", name=op.f('expert_faq_candidates_approval_status_check')),
    sa.CheckConstraint("source::text = ANY (ARRAY['expert_feedback'::character varying, 'auto_generated'::character varying]::text[])", name=op.f('expert_faq_candidates_source_check')),
    sa.CheckConstraint('estimated_monthly_savings >= 0::numeric', name=op.f('non_negative_savings')),
    sa.CheckConstraint('frequency >= 0', name=op.f('non_negative_frequency')),
    sa.ForeignKeyConstraint(['approved_by'], ['user.id'], name=op.f('expert_faq_candidates_approved_by_fkey'), ondelete='SET NULL'),
    sa.ForeignKeyConstraint(['expert_id'], ['expert_profiles.id'], name=op.f('expert_faq_candidates_expert_id_fkey'), ondelete='SET NULL'),
    sa.PrimaryKeyConstraint('id', name=op.f('expert_faq_candidates_pkey'))
    )
    op.create_index(op.f('idx_expert_faq_question_embedding_ivfflat'), 'expert_faq_candidates', ['question_embedding'], unique=False, postgresql_with={'lists': '100'}, postgresql_using='ivfflat')
    op.create_index(op.f('idx_expert_faq_candidates_status'), 'expert_faq_candidates', ['approval_status', sa.literal_column('created_at DESC')], unique=False)
    op.create_index(op.f('idx_expert_faq_candidates_priority'), 'expert_faq_candidates', [sa.literal_column('priority_score DESC'), 'approval_status'], unique=False)
    op.create_index(op.f('idx_expert_faq_candidates_expert'), 'expert_faq_candidates', ['expert_id', sa.literal_column('expert_trust_score DESC')], unique=False)
    op.create_index(op.f('idx_expert_faq_candidates_category'), 'expert_faq_candidates', ['suggested_category'], unique=False)
    op.create_table('checkpoint_migrations',
    sa.Column('v', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('v', name=op.f('checkpoint_migrations_pkey'))
    )
    op.create_table('expert_feedback',
    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), autoincrement=False, nullable=False),
    sa.Column('query_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('expert_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('feedback_type', postgresql.ENUM('correct', 'incomplete', 'incorrect', name='feedback_type'), autoincrement=False, nullable=False),
    sa.Column('category', postgresql.ENUM('normativa_obsoleta', 'interpretazione_errata', 'caso_mancante', 'calcolo_sbagliato', 'troppo_generico', name='italian_feedback_category'), autoincrement=False, nullable=True),
    sa.Column('query_text', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('original_answer', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('expert_answer', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('improvement_suggestions', postgresql.ARRAY(sa.TEXT()), server_default=sa.text("'{}'::text[]"), autoincrement=False, nullable=True),
    sa.Column('regulatory_references', postgresql.ARRAY(sa.TEXT()), server_default=sa.text("'{}'::text[]"), autoincrement=False, nullable=True),
    sa.Column('confidence_score', sa.DOUBLE_PRECISION(precision=53), server_default=sa.text('0.0'), autoincrement=False, nullable=True),
    sa.Column('time_spent_seconds', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('complexity_rating', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('processing_time_ms', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('feedback_timestamp', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('action_taken', sa.VARCHAR(length=100), autoincrement=False, nullable=True),
    sa.Column('improvement_applied', sa.BOOLEAN(), server_default=sa.text('false'), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('additional_details', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('generated_task_id', sa.VARCHAR(length=50), autoincrement=False, nullable=True),
    sa.Column('task_creation_attempted', sa.BOOLEAN(), server_default=sa.text('false'), autoincrement=False, nullable=True),
    sa.Column('task_creation_success', sa.BOOLEAN(), autoincrement=False, nullable=True),
    sa.Column('task_creation_error', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('generated_faq_id', sa.VARCHAR(length=100), autoincrement=False, nullable=True),
    sa.CheckConstraint('complexity_rating >= 1 AND complexity_rating <= 5', name=op.f('expert_feedback_complexity_rating_check')),
    sa.CheckConstraint('confidence_score >= 0.0::double precision AND confidence_score <= 1.0::double precision', name=op.f('confidence_score_range')),
    sa.CheckConstraint('time_spent_seconds > 0', name=op.f('positive_time_spent')),
    sa.ForeignKeyConstraint(['expert_id'], ['expert_profiles.id'], name=op.f('expert_feedback_expert_id_fkey'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('expert_feedback_pkey'))
    )
    op.create_index(op.f('idx_expert_feedback_type_category'), 'expert_feedback', ['feedback_type', 'category'], unique=False)
    op.create_index(op.f('idx_expert_feedback_timestamp'), 'expert_feedback', [sa.literal_column('feedback_timestamp DESC')], unique=False)
    op.create_index(op.f('idx_expert_feedback_task_id'), 'expert_feedback', ['generated_task_id'], unique=False, postgresql_where='(generated_task_id IS NOT NULL)')
    op.create_index(op.f('idx_expert_feedback_query_id'), 'expert_feedback', ['query_id'], unique=False)
    op.create_index(op.f('idx_expert_feedback_improvement_applied'), 'expert_feedback', ['improvement_applied'], unique=False, postgresql_where='(improvement_applied = false)')
    op.create_index(op.f('idx_expert_feedback_generated_faq_id'), 'expert_feedback', ['generated_faq_id'], unique=False)
    op.create_index(op.f('idx_expert_feedback_expert_id'), 'expert_feedback', ['expert_id'], unique=False)
    op.create_table('checkpoints',
    sa.Column('thread_id', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('checkpoint_ns', sa.TEXT(), server_default=sa.text("''::text"), autoincrement=False, nullable=False),
    sa.Column('checkpoint_id', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('parent_checkpoint_id', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('type', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('checkpoint', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('metadata', postgresql.JSONB(astext_type=sa.Text()), server_default=sa.text("'{}'::jsonb"), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('thread_id', 'checkpoint_ns', 'checkpoint_id', name=op.f('checkpoints_pkey'))
    )
    op.create_index(op.f('checkpoints_thread_id_idx'), 'checkpoints', ['thread_id'], unique=False)
    op.drop_index('idx_working_hours_agreement', table_name='ccnl_working_hours')
    op.drop_table('ccnl_working_hours')
    op.drop_index('idx_special_allowances_agreement_type', table_name='ccnl_special_allowances')
    op.drop_table('ccnl_special_allowances')
    op.drop_index('idx_salary_tables_dates', table_name='ccnl_salary_tables')
    op.drop_index('idx_salary_tables_agreement_level', table_name='ccnl_salary_tables')
    op.drop_table('ccnl_salary_tables')
    op.drop_index('idx_overtime_rules_agreement', table_name='ccnl_overtime_rules')
    op.drop_table('ccnl_overtime_rules')
    op.drop_index('idx_notice_periods_agreement_category', table_name='ccnl_notice_periods')
    op.drop_table('ccnl_notice_periods')
    op.drop_index('idx_leave_entitlements_agreement_type', table_name='ccnl_leave_entitlements')
    op.drop_table('ccnl_leave_entitlements')
    op.drop_index('idx_job_levels_category', table_name='ccnl_job_levels')
    op.drop_index('idx_job_levels_agreement_code', table_name='ccnl_job_levels')
    op.drop_table('ccnl_job_levels')
    op.drop_index('idx_change_logs_significance', table_name='ccnl_change_logs')
    op.drop_index('idx_change_logs_created', table_name='ccnl_change_logs')
    op.drop_index('idx_change_logs_ccnl_id', table_name='ccnl_change_logs')
    op.drop_table('ccnl_change_logs')
    op.drop_index('idx_ccnl_versions_effective', table_name='ccnl_versions')
    op.drop_index('idx_ccnl_versions_current', table_name='ccnl_versions')
    op.drop_index('idx_ccnl_versions_ccnl_id', table_name='ccnl_versions')
    op.drop_table('ccnl_versions')
    op.drop_index('idx_update_events_status', table_name='ccnl_update_events')
    op.drop_index('idx_update_events_detected', table_name='ccnl_update_events')
    op.drop_index('idx_update_events_ccnl_id', table_name='ccnl_update_events')
    op.drop_table('ccnl_update_events')
    op.drop_index('idx_ccnl_agreements_sector_valid', table_name='ccnl_agreements')
    op.drop_index('idx_ccnl_agreements_dates', table_name='ccnl_agreements')
    op.drop_table('ccnl_agreements')
    op.drop_index(op.f('ix_ccnl_sectors_sector_code'), table_name='ccnl_sectors')
    op.drop_index('idx_ccnl_sectors_priority_active', table_name='ccnl_sectors')
    op.drop_table('ccnl_sectors')
    op.drop_index('idx_monitoring_metrics_type', table_name='ccnl_monitoring_metrics')
    op.drop_index('idx_monitoring_metrics_timestamp', table_name='ccnl_monitoring_metrics')
    op.drop_table('ccnl_monitoring_metrics')
    op.drop_index('idx_ccnl_database_sector', table_name='ccnl_database')
    op.drop_index('idx_ccnl_database_code', table_name='ccnl_database')
    op.drop_index('idx_ccnl_database_active', table_name='ccnl_database')
    op.drop_table('ccnl_database')
    # ### end Alembic commands ###
