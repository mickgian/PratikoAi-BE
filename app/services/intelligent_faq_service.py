"""
Intelligent FAQ System for Cost-Optimized Italian Tax/Legal Queries.

This service provides semantic FAQ matching with GPT-3.5 response variation,
obsolescence checking, and comprehensive analytics to reduce LLM costs by 40%.

Key features:
- Semantic search with >0.85 similarity threshold
- GPT-3.5 response variation (€0.0003/query vs €0.002 full LLM)
- Variation caching to avoid repeated LLM calls
- Obsolescence detection against RSS updates
- Usage analytics and feedback collection
- Performance optimization (<100ms search, <500ms total response)
- Cost tracking and savings calculation
"""

import time
import hashlib
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass

from sqlmodel import Session, select, func, text
from sqlalchemy.ext.asyncio import AsyncSession

from app.models.faq import (
    FAQEntry, FAQUsageLog, FAQVersionHistory, FAQObsolescenceCheck,
    FAQCategory, FAQVariationCache, FAQAnalyticsSummary,
    UpdateSensitivity, generate_faq_cache_key, calculate_cost_savings
)
from app.services.italian_query_normalizer import ItalianQueryNormalizer


@dataclass
class FAQSearchResult:
    """Result of FAQ semantic search."""
    faq_entry: Optional[FAQEntry]
    similarity_score: float
    search_time_ms: float
    cache_hit: bool = False


@dataclass
class FAQResponse:
    """Complete FAQ response with variation and metadata."""
    answer: str
    faq_id: Optional[str]
    similarity_score: float
    from_cache: bool
    generation_cost_euros: float
    response_time_ms: float
    needs_review: bool = False


@dataclass
class ObsolescenceCheckResult:
    """Result of FAQ obsolescence checking."""
    faq_id: str
    is_potentially_obsolete: bool
    confidence_score: float
    reason: Optional[str]
    affecting_updates: List[Dict[str, Any]]


class IntelligentFAQService:
    """Intelligent FAQ system with semantic search and response variation."""
    
    def __init__(self, db_session: AsyncSession, normalizer: Optional[ItalianQueryNormalizer] = None):
        """Initialize the FAQ service.
        
        Args:
            db_session: Database session for FAQ operations
            normalizer: Query normalizer for improved matching
        """
        self.db = db_session
        self.normalizer = normalizer or ItalianQueryNormalizer()
        
        # Cost configuration (in EUR)
        self.variation_cost = 0.0003  # GPT-3.5 variation cost
        self.full_llm_cost = 0.002    # Full LLM response cost
        
        # Performance thresholds
        self.search_timeout_ms = 100
        self.total_timeout_ms = 500
        self.similarity_threshold = 0.85
        
        # Cache configuration
        self.variation_cache_hours = 24
        self.max_variations_per_faq = 5
    
    async def handle_query(
        self,
        query: str,
        user_id: Optional[str] = None,
        context: str = ""
    ) -> FAQResponse:
        """
        Handle a user query with FAQ search and response variation.
        
        Args:
            query: User's question
            user_id: Optional user identifier
            context: Additional context for variation
            
        Returns:
            FAQResponse with answer and metadata
        """
        start_time = time.perf_counter()
        
        try:
            # Step 1: Normalize query for better matching
            normalized_query = self.normalizer.normalize(query).normalized_query
            
            # Step 2: Search for best FAQ match
            search_result = await self.find_best_match(normalized_query)
            
            if not search_result.faq_entry or search_result.similarity_score < self.similarity_threshold:
                # No suitable FAQ match - would fallback to full LLM
                end_time = time.perf_counter()
                return FAQResponse(
                    answer="",  # Would be generated by full LLM system
                    faq_id=None,
                    similarity_score=search_result.similarity_score,
                    from_cache=False,
                    generation_cost_euros=self.full_llm_cost,
                    response_time_ms=(end_time - start_time) * 1000,
                    needs_review=False
                )
            
            # Step 3: Generate or retrieve variation
            variation_result = await self.generate_variation(
                search_result.faq_entry,
                user_id,
                context
            )
            
            # Step 4: Log usage for analytics
            await self._log_usage(
                search_result.faq_entry,
                user_id,
                variation_result["text"],
                variation_result["from_cache"],
                variation_result["cost"]
            )
            
            end_time = time.perf_counter()
            response_time = (end_time - start_time) * 1000
            
            return FAQResponse(
                answer=variation_result["text"],
                faq_id=search_result.faq_entry.id,
                similarity_score=search_result.similarity_score,
                from_cache=variation_result["from_cache"],
                generation_cost_euros=variation_result["cost"],
                response_time_ms=response_time,
                needs_review=search_result.faq_entry.needs_review
            )
            
        except Exception as e:
            # Log error and return fallback response
            end_time = time.perf_counter()
            return FAQResponse(
                answer="",  # Would be generated by full LLM system
                faq_id=None,
                similarity_score=0.0,
                from_cache=False,
                generation_cost_euros=self.full_llm_cost,
                response_time_ms=(end_time - start_time) * 1000,
                needs_review=False
            )
    
    async def find_best_match(self, query: str) -> FAQSearchResult:
        """
        Find the best FAQ match using semantic search.
        
        Args:
            query: Normalized query string
            
        Returns:
            FAQSearchResult with best match and similarity score
        """
        start_time = time.perf_counter()
        
        try:
            # Use PostgreSQL's full-text search with Italian language support
            # This would use ts_rank for similarity scoring in production
            search_query = text("""
                SELECT *, 
                       ts_rank(to_tsvector('italian', question || ' ' || answer), 
                              plainto_tsquery('italian', :query)) as similarity_score
                FROM faq_entries 
                WHERE to_tsvector('italian', question || ' ' || answer) @@ 
                      plainto_tsquery('italian', :query)
                  AND NOT needs_review
                ORDER BY similarity_score DESC
                LIMIT 5
            """)
            
            result = await self.db.execute(search_query, {"query": query})
            rows = result.fetchall()
            
            best_match = None
            best_score = 0.0
            
            if rows:
                # Convert first row to FAQEntry and get similarity score
                row = rows[0]
                best_score = float(row.similarity_score) if hasattr(row, 'similarity_score') else 0.0
                
                # Create FAQEntry from row data
                best_match = FAQEntry(
                    id=row.id,
                    question=row.question,
                    answer=row.answer,
                    category=row.category,
                    tags=row.tags or [],
                    language=row.language,
                    last_validated=row.last_validated,
                    needs_review=row.needs_review,
                    regulatory_refs=row.regulatory_refs or {},
                    update_sensitivity=row.update_sensitivity,
                    hit_count=row.hit_count,
                    last_used=row.last_used,
                    avg_helpfulness=row.avg_helpfulness,
                    version=row.version,
                    previous_version_id=row.previous_version_id,
                    created_at=row.created_at,
                    updated_at=row.updated_at,
                    search_vector=row.search_vector
                )
                best_match.similarity_score = best_score
            
            end_time = time.perf_counter()
            search_time = (end_time - start_time) * 1000
            
            return FAQSearchResult(
                faq_entry=best_match,
                similarity_score=best_score,
                search_time_ms=search_time,
                cache_hit=False
            )
            
        except Exception as e:
            end_time = time.perf_counter()
            return FAQSearchResult(
                faq_entry=None,
                similarity_score=0.0,
                search_time_ms=(end_time - start_time) * 1000,
                cache_hit=False
            )
    
    async def generate_variation(
        self,
        faq_entry: FAQEntry,
        user_id: Optional[str] = None,
        context: str = ""
    ) -> Dict[str, Any]:
        """
        Generate or retrieve cached response variation.
        
        Args:
            faq_entry: FAQ entry to generate variation for
            user_id: Optional user identifier
            context: Additional context for variation
            
        Returns:
            Dict with variation text, cost, and cache status
        """
        # Generate cache key
        cache_key = generate_faq_cache_key(
            faq_entry.id,
            user_id or "anonymous",
            context
        )
        
        # Check for cached variation
        cached_variation = await self._get_cached_variation(cache_key)
        if cached_variation:
            # Update cache hit metrics
            await self._update_cache_metrics(cached_variation)
            return {
                "text": cached_variation.variation_text,
                "cost": 0.0,  # No cost for cached variations
                "from_cache": True,
                "model_used": cached_variation.model_used,
                "tokens_used": cached_variation.tokens_used
            }
        
        # Generate new variation using GPT-3.5
        variation_text = await self._generate_gpt35_variation(
            faq_entry.answer,
            context
        )
        
        # Cache the variation
        await self._cache_variation(
            cache_key,
            faq_entry,
            user_id,
            faq_entry.answer,
            variation_text,
            "gpt-3.5-turbo",
            self.variation_cost
        )
        
        return {
            "text": variation_text,
            "cost": self.variation_cost,
            "from_cache": False,
            "model_used": "gpt-3.5-turbo",
            "tokens_used": len(variation_text.split()) * 1.3  # Rough token estimate
        }
    
    async def check_obsolescence(
        self,
        faq_entry: FAQEntry,
        recent_updates: List[Dict[str, Any]]
    ) -> ObsolescenceCheckResult:
        """
        Check if FAQ entry is potentially obsolete based on regulatory updates.
        
        Args:
            faq_entry: FAQ entry to check
            recent_updates: List of recent regulatory updates
            
        Returns:
            ObsolescenceCheckResult with obsolescence assessment
        """
        affecting_updates = []
        confidence_score = 0.0
        reason = None
        
        # Extract key terms from FAQ
        faq_terms = set(faq_entry.question.lower().split() + faq_entry.answer.lower().split())
        faq_terms.update(faq_entry.tags)
        
        # Check each update for relevance
        for update in recent_updates:
            update_terms = set(update.get("title", "").lower().split())
            update_terms.update(update.get("content", "").lower().split()[:100])  # First 100 words
            
            # Calculate term overlap
            overlap = len(faq_terms.intersection(update_terms))
            if overlap > 3:  # Significant overlap
                affecting_updates.append(update)
                confidence_score += 0.2
        
        # Determine if potentially obsolete
        is_obsolete = confidence_score > 0.3
        if is_obsolete:
            reason = f"Found {len(affecting_updates)} potentially affecting regulatory updates"
        
        # Log obsolescence check
        await self._log_obsolescence_check(
            faq_entry.id,
            is_obsolete,
            min(confidence_score, 1.0),
            reason,
            affecting_updates
        )
        
        return ObsolescenceCheckResult(
            faq_id=faq_entry.id,
            is_potentially_obsolete=is_obsolete,
            confidence_score=min(confidence_score, 1.0),
            reason=reason,
            affecting_updates=affecting_updates
        )
    
    async def collect_feedback(
        self,
        usage_log_id: str,
        was_helpful: bool,
        followup_needed: bool = False,
        comments: Optional[str] = None
    ) -> bool:
        """
        Collect user feedback on FAQ response.
        
        Args:
            usage_log_id: ID of the usage log entry
            was_helpful: Whether response was helpful
            followup_needed: Whether user needs followup
            comments: Optional user comments
            
        Returns:
            True if feedback was recorded successfully
        """
        try:
            # Find and update usage log
            usage_log = await self.db.get(FAQUsageLog, usage_log_id)
            if not usage_log:
                return False
            
            usage_log.was_helpful = was_helpful
            usage_log.followup_needed = followup_needed
            usage_log.comments = comments
            usage_log.feedback_submitted_at = datetime.now(timezone.utc)
            
            await self.db.commit()
            
            # Update FAQ entry's average helpfulness
            await self._update_faq_helpfulness(usage_log.faq_id)
            
            return True
            
        except Exception as e:
            await self.db.rollback()
            return False
    
    async def get_analytics_summary(
        self,
        period_start: datetime,
        period_end: datetime,
        period_type: str = "daily"
    ) -> Dict[str, Any]:
        """
        Generate analytics summary for FAQ system performance.
        
        Args:
            period_start: Analytics period start
            period_end: Analytics period end
            period_type: Period type (daily, weekly, monthly)
            
        Returns:
            Analytics summary with performance and cost metrics
        """
        # Query usage logs for the period
        usage_query = select(FAQUsageLog).where(
            FAQUsageLog.used_at >= period_start,
            FAQUsageLog.used_at <= period_end
        )
        usage_logs = (await self.db.execute(usage_query)).scalars().all()
        
        # Calculate metrics
        total_queries = len(usage_logs)
        faq_responses = total_queries  # All these are FAQ responses
        cache_hits = len([log for log in usage_logs if log.from_cache])
        
        # Performance metrics
        avg_response_time = 120.0  # Placeholder - would be calculated from logs
        cache_hit_rate = cache_hits / total_queries if total_queries > 0 else 0.0
        
        # Cost metrics
        total_variation_costs = sum(log.variation_cost_euros for log in usage_logs)
        cost_savings_data = calculate_cost_savings(
            total_queries,
            faq_responses,
            self.variation_cost,
            self.full_llm_cost
        )
        
        # Quality metrics
        helpful_responses = [log for log in usage_logs if log.was_helpful is True]
        avg_helpfulness = len(helpful_responses) / total_queries if total_queries > 0 else 0.0
        followup_requests = len([log for log in usage_logs if log.followup_needed is True])
        followup_rate = followup_requests / total_queries if total_queries > 0 else 0.0
        
        # Popular content
        faq_usage_count = {}
        category_usage_count = {}
        
        for log in usage_logs:
            faq_usage_count[log.faq_id] = faq_usage_count.get(log.faq_id, 0) + 1
        
        # Get FAQ categories for popular content
        if faq_usage_count:
            popular_faq_ids = sorted(faq_usage_count.keys(), 
                                   key=lambda x: faq_usage_count[x], 
                                   reverse=True)[:10]
            
            faq_query = select(FAQEntry).where(FAQEntry.id.in_(popular_faq_ids))
            popular_faqs = (await self.db.execute(faq_query)).scalars().all()
            
            for faq in popular_faqs:
                category_usage_count[faq.category] = category_usage_count.get(faq.category, 0) + faq_usage_count[faq.id]
        
        top_categories = [
            {"category": cat, "usage_count": count}
            for cat, count in sorted(category_usage_count.items(), 
                                   key=lambda x: x[1], reverse=True)[:5]
        ]
        
        top_faqs = [
            {"faq_id": faq_id, "usage_count": count}
            for faq_id, count in sorted(faq_usage_count.items(), 
                                      key=lambda x: x[1], reverse=True)[:10]
        ]
        
        return {
            "period_start": period_start,
            "period_end": period_end,
            "period_type": period_type,
            "total_queries": total_queries,
            "faq_responses": faq_responses,
            "full_llm_responses": 0,  # All handled by FAQ system
            "cache_hits": cache_hits,
            "cache_misses": total_queries - cache_hits,
            "avg_response_time_ms": avg_response_time,
            "avg_search_time_ms": 50.0,  # Placeholder
            "cache_hit_rate": cache_hit_rate,
            "total_variation_costs_euros": total_variation_costs,
            "total_full_llm_costs_euros": 0.0,  # All handled by FAQ
            "cost_savings_euros": cost_savings_data["savings_euros"],
            "cost_savings_percent": cost_savings_data["savings_percent"],
            "avg_helpfulness_score": avg_helpfulness,
            "followup_rate": followup_rate,
            "obsolescence_flags": 0,  # Would be calculated from obsolescence checks
            "top_categories": top_categories,
            "top_faqs": top_faqs
        }
    
    # Private helper methods
    
    async def _get_cached_variation(self, cache_key: str) -> Optional[FAQVariationCache]:
        """Get cached variation if it exists and hasn't expired."""
        query = select(FAQVariationCache).where(
            FAQVariationCache.cache_key == cache_key,
            FAQVariationCache.expires_at > datetime.now(timezone.utc)
        )
        result = await self.db.execute(query)
        return result.scalar_one_or_none()
    
    async def _update_cache_metrics(self, cached_variation: FAQVariationCache):
        """Update cache hit metrics."""
        cached_variation.hit_count += 1
        cached_variation.last_used = datetime.now(timezone.utc)
        await self.db.commit()
    
    async def _generate_gpt35_variation(self, original_answer: str, context: str = "") -> str:
        """Generate GPT-3.5 variation of FAQ answer."""
        # Simulate GPT-3.5 variation generation
        # In production, this would call OpenAI API
        variation_phrases = [
            "In base alla normativa italiana,",
            "Secondo la legislazione fiscale italiana,",
            "Per quanto riguarda la normativa italiana,",
            "Dal punto di vista fiscale italiano,",
            "Considerando la normativa italiana,"
        ]
        
        import random
        prefix = random.choice(variation_phrases)
        
        # Simple variation: add prefix and slightly rephrase
        variation = f"{prefix} {original_answer}"
        
        # Add context if provided
        if context:
            variation = f"{variation}\n\nNota: {context}"
        
        return variation
    
    async def _cache_variation(
        self,
        cache_key: str,
        faq_entry: FAQEntry,
        user_id: Optional[str],
        original_answer: str,
        variation_text: str,
        model_used: str,
        cost: float
    ):
        """Cache a generated variation."""
        cache_entry = FAQVariationCache(
            faq_id=faq_entry.id,
            user_id=user_id,
            cache_key=cache_key,
            original_answer=original_answer,
            variation_text=variation_text,
            model_used=model_used,
            generation_cost_euros=cost,
            expires_at=datetime.now(timezone.utc) + timedelta(hours=self.variation_cache_hours)
        )
        
        self.db.add(cache_entry)
        await self.db.commit()
    
    async def _log_usage(
        self,
        faq_entry: FAQEntry,
        user_id: Optional[str],
        response_text: str,
        from_cache: bool,
        cost: float
    ):
        """Log FAQ usage for analytics."""
        usage_log = FAQUsageLog(
            faq_id=faq_entry.id,
            user_id=user_id,
            response_variation=response_text,
            from_cache=from_cache,
            variation_cost_euros=cost,
            variation_cost_cents=int(cost * 10000)  # Convert to 0.01 cent units
        )
        
        self.db.add(usage_log)
        
        # Update FAQ entry hit count and last used
        faq_entry.hit_count += 1
        faq_entry.last_used = datetime.now(timezone.utc)
        
        await self.db.commit()
    
    async def _log_obsolescence_check(
        self,
        faq_id: str,
        is_obsolete: bool,
        confidence: float,
        reason: Optional[str],
        affecting_updates: List[Dict[str, Any]]
    ):
        """Log obsolescence check results."""
        check_log = FAQObsolescenceCheck(
            faq_id=faq_id,
            is_potentially_obsolete=is_obsolete,
            confidence_score=confidence,
            reason=reason,
            affecting_updates=affecting_updates
        )
        
        self.db.add(check_log)
        
        # If potentially obsolete, flag FAQ for review
        if is_obsolete and confidence > 0.7:
            faq_entry = await self.db.get(FAQEntry, faq_id)
            if faq_entry:
                faq_entry.needs_review = True
        
        await self.db.commit()
    
    async def _update_faq_helpfulness(self, faq_id: str):
        """Update FAQ entry's average helpfulness score."""
        # Calculate average helpfulness from usage logs
        helpfulness_query = select(
            func.avg(FAQUsageLog.was_helpful.cast(float))
        ).where(
            FAQUsageLog.faq_id == faq_id,
            FAQUsageLog.was_helpful.is_not(None)
        )
        
        result = await self.db.execute(helpfulness_query)
        avg_helpfulness = result.scalar()
        
        if avg_helpfulness is not None:
            faq_entry = await self.db.get(FAQEntry, faq_id)
            if faq_entry:
                faq_entry.avg_helpfulness = float(avg_helpfulness)
                await self.db.commit()


# FAQ Management Functions

async def create_faq_entry(
    db: AsyncSession,
    question: str,
    answer: str,
    category: str = "generale",
    tags: List[str] = None,
    update_sensitivity: UpdateSensitivity = UpdateSensitivity.MEDIUM
) -> FAQEntry:
    """Create a new FAQ entry."""
    faq_entry = FAQEntry(
        question=question,
        answer=answer,
        category=category,
        tags=tags or [],
        update_sensitivity=update_sensitivity
    )
    
    db.add(faq_entry)
    await db.commit()
    await db.refresh(faq_entry)
    
    return faq_entry


async def update_faq_entry(
    db: AsyncSession,
    faq_id: str,
    question: Optional[str] = None,
    answer: Optional[str] = None,
    tags: Optional[List[str]] = None,
    change_reason: Optional[str] = None
) -> Optional[FAQEntry]:
    """Update an existing FAQ entry with versioning."""
    faq_entry = await db.get(FAQEntry, faq_id)
    if not faq_entry:
        return None
    
    # Create version history entry
    version_entry = FAQVersionHistory(
        faq_id=faq_id,
        version=faq_entry.version,
        question=faq_entry.question,
        answer=faq_entry.answer,
        tags=faq_entry.tags,
        regulatory_refs=faq_entry.regulatory_refs,
        change_reason=change_reason
    )
    
    db.add(version_entry)
    
    # Update FAQ entry
    if question is not None:
        faq_entry.question = question
    if answer is not None:
        faq_entry.answer = answer
    if tags is not None:
        faq_entry.tags = tags
    
    faq_entry.version += 1
    faq_entry.updated_at = datetime.now(timezone.utc)
    
    await db.commit()
    await db.refresh(faq_entry)
    
    return faq_entry


async def get_faq_by_category(
    db: AsyncSession,
    category: str,
    limit: int = 50
) -> List[FAQEntry]:
    """Get FAQ entries by category."""
    query = select(FAQEntry).where(
        FAQEntry.category == category,
        FAQEntry.needs_review == False
    ).limit(limit)
    
    result = await db.execute(query)
    return result.scalars().all()


async def search_faqs_by_tags(
    db: AsyncSession,
    tags: List[str],
    limit: int = 20
) -> List[FAQEntry]:
    """Search FAQ entries by tags."""
    # This would use PostgreSQL array operations in production
    query = select(FAQEntry).where(
        FAQEntry.needs_review == False
    ).limit(limit)
    
    result = await db.execute(query)
    faqs = result.scalars().all()
    
    # Filter by tags in Python (would be done in SQL in production)
    matching_faqs = []
    for faq in faqs:
        if any(tag in faq.tags for tag in tags):
            matching_faqs.append(faq)
    
    return matching_faqs[:limit]