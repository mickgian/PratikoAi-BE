# LLM Model Configuration for PratikoAI
# Reference: PRATIKO_1.5_REFERENCE.md Section 13.10
#
# This file configures tiered LLM model selection:
# - BASIC tier: For routing, query expansion, HyDE (cost-optimized)
# - PREMIUM tier: For critical synthesis (quality-optimized)
#
# Environment variables override these values:
# - LLM_MODEL_BASIC: Override basic tier model
# - LLM_MODEL_PREMIUM: Override premium tier model
# - LLM_PROVIDER_BASIC: Override basic tier provider
# - LLM_PROVIDER_PREMIUM: Override premium tier provider

version: "1.0"

# Tier configurations
tiers:
  # BASIC tier: Used for routing, query expansion, HyDE
  # Lower cost, faster response times
  basic:
    provider: openai
    model: gpt-4o-mini
    timeout_ms: 30000
    temperature: 0.3
    max_tokens: 2000

  # PREMIUM tier: Used for critical synthesis (Step 64)
  # Higher quality, supports complex reasoning
  premium:
    provider: openai
    model: gpt-4o
    timeout_ms: 60000
    temperature: 0.2
    max_tokens: 4000
    # Fallback to Anthropic if OpenAI fails
    fallback:
      provider: anthropic
      model: claude-3-5-sonnet-20241022
      timeout_ms: 90000

# Default values for any missing tier configuration
defaults:
  provider: openai
  model: gpt-4o-mini
  timeout_ms: 30000
  temperature: 0.3
  max_tokens: 2000

# Known valid models for validation
known_models:
  openai:
    - gpt-4o-mini
    - gpt-4o
    - gpt-4-turbo
    - gpt-3.5-turbo
  anthropic:
    - claude-3-5-sonnet-20241022
    - claude-3-haiku-20240307
    - claude-3-opus-20240229
