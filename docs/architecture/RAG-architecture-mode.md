# RAG Architecture Migration Plan

**Mode: Tiered Graph Hybrid**

## Definitions

### Node (runtime boundary)
Explicit runtime step where state crosses a boundary (LLM calls, caching, provider routing, streaming, compliance gates).

- Must be represented as explicit graph nodes
- Have retries, metrics, and feature flags
- Clear inbound/outbound edges

### Internal (pure transform)
Deterministic functions executed inside a Node boundary.

- No retries, no state isolation
- Called directly by a Node wrapper
- Covered by unit tests and Node-level parity tests

## Canonical Node Set (~35 promoted)

Everything not listed here remains **Internal**.

### Request / Privacy
- 1 ValidateRequest
- 3 ValidCheck
- 6 PrivacyCheck
- 9 PIICheck

### Golden / Cache
- 20 GoldenFastGate
- 24 GoldenLookup
- 26 KBContextCheck
- 59 CheckCache
- 62 CacheHit

### Classification / Routing
- 31 DomainClassification
- 42 ClassificationConfidence
- 48 SelectProvider
- 50 RoutingStrategy
- 55 EstimateCost
- 56 CostCheck

### LLM / Tools
- 64 LLMCall
- 67 LLMSuccess
- 75 ToolCheck
- 79 ToolType
- 80 KBTool
- 81 CCNLTool
- 82 DocumentIngestTool
- 83 FAQTool

### Response / Streaming
- 104 StreamCheck
- 105 StreamSetup
- 109 StreamResponse
- 112 End

## Phase 0 â€” Align & Freeze
**Status:** âœ… Implemented
**Goal:** Lock the Tiered Graph Hybrid target (~35 Nodes, ~100 Internals).
**Deliverable:** This doc + team ACK in PR comments.

**Gate:** PR comment from the team: "We're doing Tiered Graph Hybrid."

## Phase 1 â€” Documentation Sync
**Status:** âœ… Implemented
**Goal:** Make docs reflect reality so audits are meaningful.

Update every `docs/architecture/steps/STEP-*.md`:

- **Role:** Node | Internal
- **Status:** 
  - Node â†’ âœ… Implemented / ğŸ”Œ Not wired / âŒ Missing
  - Internal â†’ ğŸ”Œ Implemented (internal) / âŒ Missing
- **Paths / classes:** 1â€“3 file:line â€” symbol entries
- **Behavior notes:** brief; include nearest Node and neighbors if Node

Edit Mermaid nodes to show badges: `[S<step>] {Node|Internal}`

**Example:**
```
ValidateRequest[[S1 Validate request {Node}]]
```

**Run tooling:**
```bash
python scripts/rag_code_graph.py --write
python scripts/rag_audit.py --write
```

**Gate (dashboard):**
- Node steps must be wired
- Internal steps only need to be implemented

## Phase 1A â€” Initial Node Promotion (complete)

**Status:** âœ… Implemented and active (default).

**Promoted Nodes (9):**
- 1 ValidateRequest
- 3 ValidCheck
- 6 PrivacyCheck
- 9 PIICheck
- 59 CheckCache
- 62 CacheHit
- 64 LLMCall
- 67 LLMSuccess
- 112 End

**Implementation notes:**
- RAGState type created (extends existing GraphState)
- 9 thin Node wrappers calling existing `step_N__*` orchestrators
- Edges wired in `create_graph_phase1a()`
- Now the default implementation (no feature flag needed)
- Tests: unit, integration, parity

## Phase 2 â€” Audit Rules Update (Â½ day)

**Goal:** Make audits fair to hybrid mode.

**Rules:**
- If Role=Node â†’ must be wired in LangGraph to pass
- If Role=Internal â†’ pass if implemented & referenced by a Node path

**Gate:** Rerun audit shows green for Internal steps that used to read âŒ/ğŸ”Œ.

## Phase 3 â€” Implementation Scaffolding (1â€“2 days, no behavior change)

**Goal:** Prepare safe wrappers & state.

**Tasks:**
- Finalize RAGState (request/user/session, privacy flags, facts, attachments, golden hit, KB docs, provider choice, cache key, LLM response, tool results, streaming flags, metrics)
- Create Node wrappers (for all ~35 promoted steps) that call existing internal code
- Add `rag_step_log(...)` + `rag_step_timer(...)`
- Parity tests: snapshot real conversations; assert identical outputs with/without wrappers

**Gate:** All parity tests pass.

## Phase 4 â€” Cache â†’ LLM â†’ Tools Lane (2â€“3 days)

**Goal:** Wire the hot path; keep pure transforms internal.

**Nodes & edges:**
```
59 CheckCache â†’ 62 CacheHit?
  â”œâ”€ Yes â†’ 66 ReturnCached â†’ 101/112
  â””â”€ No  â†’ 64 LLMCall â†’ 67 LLMSuccess?
              â”œâ”€ Yes â†’ 68 CacheResponse â†’ 74 TrackUsage
              â””â”€ No  â†’ 69 RetryCheck â†’ 70 ProdCheck â†’ (72 Failover | 73 RetrySame)
          â†’ 75 ToolCheck â†’ 79 ToolType â†’ (80 KB | 81 CCNL | 82 Doc | 83 FAQ) â†’ 99 ToolResults
```

**Metrics:** cache hit%, LLM retry rate, tool failure rate.

**Gates:** Parity green; latency & cost stable in canary; audit marks these Nodes as wired âœ….

## Phase 5 â€” Provider Governance Lane (2â€“3 days)

**Goal:** Make routing & cost explicit and observable.

**Nodes:**
```
48 SelectProvider â†’ 49 RouteStrategy â†’ 50 StrategyType â†’ (51/52/53/54) â†’ 55 EstimateCost â†’ 56 CostCheck â†’ (57 CreateProvider | 58 CheaperProvider)
```

**Policies:** per-route budgets, caps, A/B routes, kill switches.
**Metrics:** route distribution, cost/turn, cost rejections.
**Gate:** Cost regression tests pass; decisions observable in logs/dashboards.

## Phase 6 â€” Request / Privacy Lane (1â€“2 days)

**Goal:** Enforce compliance gates.

**Nodes:**
```
1 ValidateRequest â†’ 3 ValidCheck â†’ (4 GDPRLog) â†’ 6 PrivacyCheck â†’ (7 AnonymizeText â†’ 9 PIICheck â†’ 10 LogPII) â†’ 8 InitAgent
```

**Policies:** hard reject invalid requests; GDPR evidence logs.
**Gate:** Negative tests pass (bad request, privacy disabled, etc.); audit logs present.

## Phase 7 â€” Streaming / Response Lane (1â€“2 days)

**Goal:** Isolate streaming from compute.

**Nodes:**
```
104 StreamCheck â†’ (105 StreamSetup â†’ 106 AsyncGen â†’ 107 SinglePass â†’ 108 WriteSSE â†’ 109 StreamResponse â†’ 110 SendDone) â†’ 111 CollectMetrics â†’ 112 End
```

**Gate:** Streaming stability & metrics visible; non-stream path unaffected.

## Phase 8 â€” Golden / KB Gates (2â€“3 days)

**Goal:** Golden fast-path + KB recency checks.

**Nodes:**
```
20 GoldenFastGate â†’ (24 GoldenLookup â†’ 25 GoldenHit â†’ 26 KBContextCheck â†’ 27 KBDelta â†’ 28 ServeGolden â†’ 30 ReturnComplete)
(Branch to KB path when needed.)
```

**Metrics:** golden hit% and KB override% by signature.
**Gate:** Golden answers served with citations; fallbacks verified.

## Phase 9 â€” Test Suite Hardening (parallel)

**Goal:** Ensure comprehensive testing across all lanes.

**Tasks:**
- Parity tests per lane
- Lane integration tests (prev â†’ this â†’ next)
- Failure injection (cache miss/hit, provider budget fail, tool timeout, stream disconnect)
- Performance budgets: P95 latency caps per lane

**Gate:** CI fast & reliable; red tests are actionable.

## Phase 10 â€” Rollout & Ops (2â€“4 days)

**Goal:** Ship safely with toggles.

**Feature flags per lane:**
- `cache_llm_lane`
- `tools_lane`
- `provider_lane`
- `privacy_lane`
- `streaming_lane`
- `golden_lane`

**Canary:** 5% â†’ 25% â†’ 50% â†’ 100%

**Dashboards:** cache hit%, LLM retries, tool error rate, latency by lane, token cost/turn

**On incident:** flip off only the offending lane

**Gate:** All lanes at 100%, SLOs hold.

## PR Discipline (keep it small)

- **PR 1:** Phase 0â€“1 (docs only)
- **PR 2:** Scaffolding (state + node wrappers, no behavior change)
- **PR 3:** Cacheâ†’LLMâ†’Tools lane
- **PR 4:** Provider governance lane
- **PR 5:** Request/Privacy lane
- **PR 6:** Streaming/Response lane
- **PR 7:** Golden/KB gates

*(Tests & dashboards can land alongside each PR.)*

## Success Criteria

- **Conformance:** All Node steps wired âœ…; Internal steps marked Implemented (internal)
- **Ops:** â†‘ cache hit%, LLM retry% < 2%, tool failures isolated, faster triage
- **Cost:** 5â€“20% token savings (cache + provider governance)
- **Compliance:** Deterministic logs at request/privacy gates

## Handy Commands

### Refresh graph & audit:
```bash
python scripts/rag_code_graph.py --write
python scripts/rag_audit.py --write
```

### Run parity & integration tests (adapt to your names):
```bash
pytest -k "parity or lane or rag_step"
```

### Run the application with Phase 1A graph (now default):
```bash
uvicorn app.main:app --reload
```