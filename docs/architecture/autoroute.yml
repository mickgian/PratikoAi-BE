# Where to inject orchestrator calls for each pipeline slice.
# Paths are relative to repo root.

slices:

  entry:
    target_file: app/core/langgraph/graph.py
    target_function: get_response
    steps: [2, 1, 3, 4, 6, 7, 9, 10, 8, 11, 12, 13]   # Start → ValidateRequest → ValidCheck → GDPR → … → ExtractQuery → MessageExists

  extract_and_facts:
    target_file: app/core/langgraph/graph.py
    target_function: _classify_user_query
    steps: [14, 16, 17, 18]   # ExtractFacts, CanonicalizeFacts, AttachmentFingerprint, QuerySig

  preflight_golden_gate:
    target_file: app/core/langgraph/graph.py
    target_function: _classify_user_query
    steps: [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]  # Attachments check → Golden fast path → … → PreContextFromGolden

  kb_and_context:
    target_file: app/core/langgraph/graph.py
    target_function: _build_context   # adjust if your helper is differently named
    steps: [39, 40]                   # KBPreFetch, BuildContext

  prompting:
    target_file: app/core/langgraph/graph.py
    target_function: _get_system_prompt
    steps: [41, 42, 43, 44, 45, 46, 47]  # SelectPrompt → ClassConfidence → DomainPrompt/Default → CheckSysMsg → Replace/Insert

  providers:
    target_file: app/core/langgraph/graph.py
    target_function: _get_optimal_provider
    steps: [48, 49, 50, 51-58]  # SelectProvider → RouteStrategy → StrategyType → 51..58

  cache_and_llm:
    target_file: app/core/langgraph/graph.py
    target_function: _get_cached_llm_response
    steps: [59, 60, 61, 62, 63, 65, 66, 68]   # CheckCache path + CacheResponse

  llm_execute_and_retry:
    target_file: app/core/langgraph/graph.py
    target_function: _call_llm_provider   # adjust if named differently
    steps: [64, 67, 69, 70, 71, 72, 73]   # LLMCall → LLMSuccess → Retry/Prod → Error/Failover/RetrySame

  tools_and_docs:
    target_file: app/core/langgraph/graph.py
    target_function: _tool_call
    steps: [75, 76, 77, 78, 79, 80-83, 84, 85, 86, 87, 88, 89, 90-98, 99] # tool paths + document ingest pipeline

  response_pipeline:
    target_file: app/core/langgraph/graph.py
    target_function: __process_messages
    steps: [101, 102, 103, 104, 105-110, 112]  # FinalResponse → ProcessMsg → logging → streaming → return

  metrics_feedback_golden:
    target_file: app/core/langgraph/graph.py
    target_function: get_response   # feedback is post-response; hook at end of request
    steps: [111, 113-131]           # CollectMetrics + feedback + golden mgmt

  rss_background:
    target_file: app/core/langgraph/graph.py
    target_function: get_response   # or a background scheduler module if you have one
    steps: [132, 133, 134, 135]     # RSS monitor chain
