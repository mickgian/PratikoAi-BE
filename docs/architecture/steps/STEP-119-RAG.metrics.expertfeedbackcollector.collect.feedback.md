# RAG STEP 119 â€” ExpertFeedbackCollector.collect_feedback (RAG.metrics.expertfeedbackcollector.collect.feedback)

**Type:** process  
**Category:** metrics  
**Node ID:** `ExpertFeedbackCollector`

## Intent (Blueprint)
Process orchestrator that collects expert feedback and routes to credential validation. Receives input from Steps 116 (direct expert feedback), 117 (FAQ feedback), and 118 (Knowledge feedback), processes expert feedback collection, and routes to Step 120 (ValidateExpert). Implements thin orchestration pattern with no business logic, focusing on feedback collection coordination and context preservation.

## Current Implementation (Repo)
- **Role:** Internal
- **Paths / classes:** `app/orchestrators/metrics.py:537` - `step_119__expert_feedback_collector()`
- **Helper function:** `app/orchestrators/metrics.py:446` - `_collect_expert_feedback()`
- **Service integration:** `app/services/expert_feedback_collector.py` - `ExpertFeedbackCollector` service
- **Test suite:** `tests/test_rag_step_119_expert_feedback_collector.py` (16 comprehensive tests)
- **Status:** âœ… Implemented (async process orchestrator with expert feedback collection)
- **Behavior notes:**
  - Collects expert feedback with comprehensive validation and processing
  - Routes to Step 120 (ValidateExpert) per Mermaid diagram
  - Handles multiple input sources: direct expert feedback, FAQ feedback, knowledge feedback
  - Processes Italian feedback categories for tax professionals
  - Validates expert credentials and trust scoring preparation
  - Preserves all context data while adding expert feedback metadata
  - Handles errors gracefully with fallback routing

## Differences (Blueprint vs Current)
- âœ… Fully implemented as async process orchestrator following thin orchestration pattern
- âœ… Added comprehensive expert feedback collection and validation logic
- âœ… Added Italian feedback category processing for tax professionals
- âœ… Added expert trust scoring and validation preparation
- âœ… Added priority-based feedback processing (incorrect/incomplete = high priority)
- âœ… Added error handling with graceful fallback to credential validation
- âœ… Added performance tracking with feedback collection timing
- âœ… Added comprehensive observability with structured logging
- âœ… Integrated with existing ExpertFeedbackCollector service

## Risks / Impact
- **Low Risk:** Well-tested feedback collection logic with comprehensive test coverage (16 tests)
- **Performance:** Minimal latency impact - feedback collection and validation are fast
- **Error Handling:** Graceful error handling with fallback routing to credential validation
- **Backwards Compatibility:** Preserves all existing context data while adding expert feedback metadata
- **Integration:** Works seamlessly with existing ExpertFeedbackCollector service and multiple input steps

## TDD Task List
- [x] Unit tests: 10 comprehensive test cases covering feedback collection, validation, and error scenarios
- [x] Integration tests: 5 integration tests covering Step 116â†’119, 117â†’119, 118â†’119, 119â†’120, and full pipeline flows
- [x] Implementation changes:
  - [x] Converted sync stub to async process orchestrator
  - [x] Added `_collect_expert_feedback()` helper function with validation logic
  - [x] Added expert feedback collection processing and validation
  - [x] Added Italian feedback category processing and localization
  - [x] Added expert trust scoring and validation requirements
  - [x] Added priority-based feedback processing logic
  - [x] Added comprehensive error handling with multiple error types
  - [x] Added performance tracking and feedback collection timing
  - [x] Added context preservation and routing to Step 120
- [x] Observability: added structured log lines
  `RAG STEP 119 (RAG.metrics.expertfeedbackcollector.collect.feedback): ExpertFeedbackCollector.collect_feedback | attrs={...}`
- [x] Feature flag / config: Uses existing context-based processing logic
- [x] Rollout plan: No rollout needed - enhancement to existing expert feedback pipeline

## Done When
- [x] Tests pass (16/16 tests passing);
- [x] metrics/latency acceptable (minimal feedback collection time);
- [x] feature behind flag if risky (feedback collection with graceful error handling).

## Links
- RAG Diagram: `docs/architecture/diagrams/pratikoai_rag.mmd`
- Step registry: `docs/architecture/rag_steps.yml`


<!-- AUTO-AUDIT:BEGIN -->
Role: Internal  |  Status: ðŸ”Œ (Implemented - internal)  |  Confidence: 0.35

Top candidates:
1) app/orchestrators/metrics.py:448 â€” app.orchestrators.metrics._collect_expert_feedback (score 0.35)
   Evidence: Score 0.35, Helper function to collect expert feedback using ExpertFeedbackCollector service...
2) app/services/expert_feedback_collector.py:43 â€” app.services.expert_feedback_collector.ExpertFeedbackCollector.__init__ (score 0.35)
   Evidence: Score 0.35, method: __init__
3) app/services/expert_feedback_collector.py:31 â€” app.services.expert_feedback_collector.ExpertFeedbackCollector (score 0.34)
   Evidence: Score 0.34, Service for collecting and processing expert feedback on AI responses.

Features...
4) app/services/expert_feedback_collector.py:149 â€” app.services.expert_feedback_collector.ExpertFeedbackCollector._validate_feedback_data (score 0.34)
   Evidence: Score 0.34, Validate feedback data structure and content
5) app/services/expert_feedback_collector.py:297 â€” app.services.expert_feedback_collector.ExpertFeedbackCollector._update_statistics (score 0.34)
   Evidence: Score 0.34, Update internal statistics tracking

Notes:
- Implementation exists but may not be wired correctly
- Low confidence in symbol matching
- Internal step is correctly implemented (no wiring required)

Suggested next TDD actions:
- Connect existing implementation to RAG workflow
- Add integration tests for end-to-end flow
- Verify error handling and edge cases
<!-- AUTO-AUDIT:END -->