# Backend API Integration Guide

## Overview

The chat interface has been successfully integrated with the real PratikoAI backend API using Test-Driven Development (TDD) methodology. This guide explains how to test and use the real API integration.

## âœ… Implementation Status

### Completed Components

- âœ… **SSE Connection Tests** - Comprehensive tests for Server-Sent Events streaming
- âœ… **Real API Streaming Service** - Production-ready service for backend communication
- âœ… **Second Message Test** - Critical test ensuring sequential messages work correctly
- âœ… **ChatInputArea Integration** - Updated to use real API instead of mock service
- âœ… **Complete Flow Tests** - Integration tests covering all user scenarios

### Key Features Implemented

- **HTML-aware streaming** - Preserves HTML structure during progressive display
- **Message format conversion** - Converts UI messages to API format automatically
- **Session management** - Automatic session creation and token handling
- **Input mode context** - Adds appropriate system messages based on selected mode
- **Error handling** - Graceful recovery from network and API errors
- **Connection cleanup** - Prevents memory leaks and duplicate connections

## ğŸ”§ Backend Requirements

### Environment Setup

Ensure your `.env.local` contains:

```bash
NEXT_PUBLIC_API_URL=http://localhost:8000
```

### Backend Verification

Before testing, verify backend is running:

```bash
# Check if backend is accessible
curl http://localhost:8000/docs

# Should return PratikoAI API documentation
```

### Required Backend Features

The backend must support:

- **POST** `/api/v1/chatbot/chat/stream` - SSE streaming endpoint
- **POST** `/api/v1/auth/session` - Session creation
- **Authentication** via Bearer tokens
- **CORS** enabled for frontend origin

## ğŸ§ª Testing the Integration

### 1. Run the Test Suite

```bash
# Run all API integration tests
npm test -- --testPathPatterns="SSEConnection|SecondMessage|RealAPIIntegration"

# Run specific critical tests
npm test -- src/app/chat/tests/api/SecondMessage.test.tsx
```

### 2. Manual Testing Sequence

1. **Start Development Server**

   ```bash
   npm run dev
   # Opens on http://localhost:3003
   ```

2. **Open Chat Interface**
   - Navigate to http://localhost:3003/chat
   - You should see the welcome screen

3. **First Message Test**
   - Type: "Come funziona il regime forfettario?"
   - Press Enter
   - **Expected**: Real AI response streams with typing effect

4. **Second Message Test (CRITICAL)**
   - After first response completes
   - Type: "Quali sono i limiti?"
   - Press Enter
   - **Expected**: Second response streams correctly without issues

5. **Sequential Messages Test**
   - Continue sending multiple messages
   - **Expected**: Each message gets a proper response

6. **Input Mode Testing**
   - Switch between Simple, Complex, Interactive, Document modes
   - Send messages in each mode
   - **Expected**: System context added for non-simple modes

## ğŸ“‹ Success Criteria Checklist

### Essential Functionality

- [ ] Backend responds on http://localhost:8000
- [ ] First message receives real AI response
- [ ] **Second message works perfectly** (critical requirement)
- [ ] HTML formatting preserved during streaming
- [ ] Typing effect smooth with proper timing
- [ ] Error messages shown for connection failures

### Advanced Features

- [ ] Input modes add appropriate context
- [ ] Session persistence across messages
- [ ] Message history included in API calls
- [ ] Network errors handled gracefully
- [ ] Component cleanup prevents memory leaks

## ğŸš¨ Common Issues & Solutions

### Backend Not Running

```
âŒ Error: "Impossibile connettersi al server"
âœ… Solution: Start PratikoAI backend on port 8000
```

### Authentication Issues

```
âŒ Error: "Utente non autenticato"
âœ… Solution: Ensure user is logged in before using chat
```

### CORS Problems

```
âŒ Error: "CORS policy blocked request"
âœ… Solution: Configure backend to allow frontend origin
```

### Second Message Fails

```
âŒ Error: Messages after first don't work
âœ… Solution: Check session token handling and connection cleanup
```

## ğŸ”„ Switching Back to Mock Service

If backend is unavailable, you can temporarily revert to mock service:

1. **Update ChatInputArea.tsx**:

   ```text
   // Replace this import:
   import { createRealAPIStreamingService } from '../services/RealAPIStreamingService'

   // With these imports:
   import { MockStreamingService } from '../services/MockStreamingService'
   import { MockResponseService } from '../services/MockResponseService'
   ```

2. **Update handleSendMessage** to use MockStreamingService (refer to previous implementation)

## ğŸ“Š Test Coverage

### API Connection Tests

- âœ… SSE connection establishment
- âœ… Chunk reception and parsing
- âœ… Connection cleanup
- âœ… Error handling
- âœ… Session management

### Message Flow Tests

- âœ… First message success
- âœ… **Second message success** (critical)
- âœ… Sequential unlimited messages
- âœ… Message format conversion
- âœ… Input mode integration

### Integration Tests

- âœ… Complete user flow
- âœ… UI component integration
- âœ… State management
- âœ… Error recovery
- âœ… Performance optimization

## ğŸ¯ Key Architectural Decisions

### Message Format Conversion

- UI messages (id, type, content, timestamp) â†’ API messages (role, content)
- Automatic role mapping: 'user' â†’ 'user', 'ai' â†’ 'assistant'

### Session Management

- Automatic session creation when none exists
- Token persistence in localStorage
- Reuse existing sessions for multiple messages

### Streaming Architecture

- Real-time SSE connection per message
- Progressive HTML chunk assembly
- Immediate connection cleanup on completion

### Error Handling Strategy

- Network errors: User-friendly Italian messages
- API errors: Display backend error details
- Recovery: Allow retry after errors

## ğŸ“ˆ Performance Considerations

### Optimizations Implemented

- **Single SSE connection per message** - No duplicate connections
- **Immediate cleanup** - Prevents memory leaks
- **Progressive rendering** - Smooth typing effect
- **Session reuse** - Reduces API calls

### Monitoring Points

- SSE connection duration
- Message processing time
- Error rates and recovery
- Memory usage during streaming

---

## âš¡ Quick Start

For immediate testing when backend is ready:

1. `npm run dev`
2. Navigate to http://localhost:3003/chat
3. Send message: "Come funziona il regime forfettario?"
4. Verify real AI response with typing effect
5. Send second message: "Calcola IRPEF per 50000 euro"
6. **Verify second message works correctly** âœ¨

The real API integration is ready for production use! ğŸš€
