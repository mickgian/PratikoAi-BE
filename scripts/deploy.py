#!/usr/bin/env python3
"""
Advanced Zero-Downtime Deployment System for PratikoAI
Implements sophisticated deployment strategies with comprehensive monitoring,
automated rollbacks, and cross-service coordination.

This system supports:
- Blue-Green deployments for infrastructure changes  
- Canary deployments for gradual rollouts
- Rolling updates for standard deployments
- Automated health checks and rollbacks
- Cross-service dependency management
- Real-time monitoring and alerting
"""

import asyncio
import boto3
import json
import os
import sys
import time
import logging
import argparse
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('deployment.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)


class DeploymentStrategy(Enum):
    """Available deployment strategies."""
    ROLLING = "rolling"
    BLUE_GREEN = "blue-green"
    CANARY = "canary"
    FAST = "fast"


class DeploymentStatus(Enum):
    """Deployment status states."""
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    HEALTH_CHECK = "health_check"
    CANARY_ANALYSIS = "canary_analysis"
    COMPLETED = "completed"
    FAILED = "failed"
    ROLLED_BACK = "rolled_back"


@dataclass
class DeploymentConfig:
    """Configuration for deployment execution."""
    service_name: str
    environment: str
    image_uri: str
    strategy: DeploymentStrategy
    desired_count: int
    
    # Health check configuration
    health_check_timeout: int = 300
    health_check_interval: int = 15
    health_check_path: str = "/health"
    
    # Canary configuration
    canary_percentage: int = 10
    canary_duration: int = 300
    canary_success_threshold: float = 99.0
    
    # Rollback configuration
    auto_rollback: bool = True
    rollback_timeout: int = 600
    
    # Notification configuration
    slack_webhook: Optional[str] = None
    email_recipients: List[str] = None


@dataclass
class HealthCheckResult:
    """Result of a health check operation."""
    endpoint: str
    status_code: int
    response_time: float
    healthy: bool
    details: Dict[str, Any]


@dataclass
class DeploymentMetrics:
    """Metrics collected during deployment."""
    start_time: datetime
    end_time: Optional[datetime] = None
    duration: Optional[float] = None
    health_checks_passed: int = 0
    health_checks_failed: int = 0
    error_rate: float = 0.0
    response_time_p95: float = 0.0
    rollback_triggered: bool = False


class AWSDeploymentManager:
    """Manages AWS ECS deployments with advanced strategies."""
    
    def __init__(self, region: str = "us-east-1"):
        self.region = region
        
        # AWS clients
        self.ecs_client = boto3.client('ecs', region_name=region)
        self.elbv2_client = boto3.client('elbv2', region_name=region)
        self.cloudwatch_client = boto3.client('cloudwatch', region_name=region)
        self.logs_client = boto3.client('logs', region_name=region)
        
        # Deployment tracking
        self.deployment_history: List[Dict[str, Any]] = []
        
    async def deploy(self, config: DeploymentConfig) -> bool:
        """Execute deployment with specified strategy."""
        
        logger.info(f"üöÄ Starting {config.strategy.value} deployment for {config.service_name}")
        logger.info(f"   Environment: {config.environment}")
        logger.info(f"   Image: {config.image_uri}")
        logger.info(f"   Desired Count: {config.desired_count}")
        
        # Initialize metrics
        metrics = DeploymentMetrics(start_time=datetime.utcnow())
        
        try:
            # Pre-deployment validation
            if not await self._pre_deployment_checks(config):
                logger.error("‚ùå Pre-deployment checks failed")
                return False
            
            # Execute deployment based on strategy
            success = False
            if config.strategy == DeploymentStrategy.BLUE_GREEN:
                success = await self._blue_green_deployment(config, metrics)
            elif config.strategy == DeploymentStrategy.CANARY:
                success = await self._canary_deployment(config, metrics)
            elif config.strategy == DeploymentStrategy.ROLLING:
                success = await self._rolling_deployment(config, metrics)
            elif config.strategy == DeploymentStrategy.FAST:
                success = await self._fast_deployment(config, metrics)
            
            # Finalize metrics
            metrics.end_time = datetime.utcnow()
            metrics.duration = (metrics.end_time - metrics.start_time).total_seconds()
            
            # Save deployment record
            await self._save_deployment_record(config, metrics, success)
            
            # Send notifications
            await self._send_notifications(config, metrics, success)
            
            if success:
                logger.info(f"‚úÖ Deployment completed successfully in {metrics.duration:.1f}s")
            else:
                logger.error(f"‚ùå Deployment failed after {metrics.duration:.1f}s")
            
            return success
            
        except Exception as e:
            logger.error(f"‚ùå Deployment failed with exception: {str(e)}")
            metrics.end_time = datetime.utcnow()
            metrics.duration = (metrics.end_time - metrics.start_time).total_seconds()
            await self._save_deployment_record(config, metrics, False)
            return False
    
    async def _pre_deployment_checks(self, config: DeploymentConfig) -> bool:
        """Comprehensive pre-deployment validation."""
        
        logger.info("üîç Running pre-deployment checks...")
        
        checks = [
            ("ECS Cluster Status", self._check_ecs_cluster_status, config),
            ("Service Exists", self._check_service_exists, config),
            ("Task Definition Valid", self._check_task_definition, config),
            ("Load Balancer Health", self._check_load_balancer_health, config),
            ("Database Connectivity", self._check_database_connectivity, config),
            ("External Dependencies", self._check_external_dependencies, config)
        ]
        
        for check_name, check_func, check_config in checks:
            logger.info(f"  üîÑ {check_name}...")
            try:
                if await check_func(check_config):
                    logger.info(f"    ‚úÖ {check_name} passed")
                else:
                    logger.error(f"    ‚ùå {check_name} failed")
                    return False
            except Exception as e:
                logger.error(f"    ‚ùå {check_name} failed with error: {str(e)}")
                return False
        
        logger.info("‚úÖ All pre-deployment checks passed")
        return True
    
    async def _blue_green_deployment(self, config: DeploymentConfig, metrics: DeploymentMetrics) -> bool:
        """Execute blue-green deployment strategy."""
        
        logger.info("üîµüü¢ Executing Blue-Green deployment")
        
        cluster_name = f"praktiko-{config.environment}"
        service_name = f"praktiko-{config.service_name}-{config.environment}"
        
        try:
            # Step 1: Create new task definition
            logger.info("üìã Creating new task definition...")
            new_task_def_arn = await self._create_task_definition(config)
            if not new_task_def_arn:
                return False
            
            # Step 2: Get current service configuration
            current_service = await self._get_service_config(cluster_name, service_name)
            if not current_service:
                return False
            
            # Step 3: Create new service (Green)
            green_service_name = f"{service_name}-green"
            logger.info(f"üü¢ Creating green service: {green_service_name}")
            
            green_service_arn = await self._create_green_service(
                cluster_name, green_service_name, new_task_def_arn, config
            )
            if not green_service_arn:
                return False
            
            # Step 4: Wait for green service to be stable
            logger.info("‚è≥ Waiting for green service to stabilize...")
            if not await self._wait_for_service_stable(cluster_name, green_service_name, 600):
                await self._cleanup_green_service(cluster_name, green_service_name)
                return False
            
            # Step 5: Health check green service
            logger.info("ü©∫ Health checking green service...")
            green_endpoint = await self._get_service_endpoint(cluster_name, green_service_name)
            if not await self._comprehensive_health_check(green_endpoint, config, metrics):
                await self._cleanup_green_service(cluster_name, green_service_name)
                return False
            
            # Step 6: Switch traffic to green service
            logger.info("üîÑ Switching traffic to green service...")
            if not await self._switch_traffic_to_green(config, green_service_name):
                await self._cleanup_green_service(cluster_name, green_service_name)
                return False
            
            # Step 7: Monitor traffic for stability
            logger.info("üìä Monitoring traffic stability...")
            if not await self._monitor_traffic_stability(config, metrics, 180):
                logger.warning("‚ö†Ô∏è Traffic instability detected, rolling back...")
                await self._switch_traffic_to_blue(config, service_name)
                await self._cleanup_green_service(cluster_name, green_service_name)
                return False
            
            # Step 8: Cleanup old blue service
            logger.info("üßπ Cleaning up old blue service...")
            await self._cleanup_blue_service(cluster_name, service_name)
            
            # Step 9: Rename green service to primary
            await self._rename_green_to_primary(cluster_name, green_service_name, service_name)
            
            logger.info("‚úÖ Blue-Green deployment completed successfully")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Blue-Green deployment failed: {str(e)}")
            return False
    
    async def _canary_deployment(self, config: DeploymentConfig, metrics: DeploymentMetrics) -> bool:
        """Execute canary deployment strategy."""
        
        logger.info(f"üê¶ Executing Canary deployment ({config.canary_percentage}% traffic)")
        
        cluster_name = f"praktiko-{config.environment}"
        service_name = f"praktiko-{config.service_name}-{config.environment}"
        
        try:
            # Step 1: Create new task definition
            logger.info("üìã Creating new task definition...")
            new_task_def_arn = await self._create_task_definition(config)
            if not new_task_def_arn:
                return False
            
            # Step 2: Calculate canary instance count
            canary_count = max(1, int(config.desired_count * config.canary_percentage / 100))
            stable_count = config.desired_count - canary_count
            
            logger.info(f"üéØ Canary instances: {canary_count}, Stable instances: {stable_count}")
            
            # Step 3: Deploy canary instances
            logger.info("üê¶ Deploying canary instances...")
            canary_service_name = f"{service_name}-canary"
            
            canary_service_arn = await self._create_canary_service(
                cluster_name, canary_service_name, new_task_def_arn, canary_count, config
            )
            if not canary_service_arn:
                return False
            
            # Step 4: Configure load balancer for canary traffic
            logger.info(f"‚öñÔ∏è Configuring {config.canary_percentage}% traffic to canary...")
            if not await self._configure_canary_traffic(config, canary_service_name):
                await self._cleanup_canary_service(cluster_name, canary_service_name)
                return False
            
            # Step 5: Monitor canary performance
            logger.info(f"üìä Monitoring canary for {config.canary_duration}s...")
            canary_success = await self._monitor_canary_performance(
                config, metrics, config.canary_duration
            )
            
            if not canary_success:
                logger.warning("‚ö†Ô∏è Canary analysis failed, rolling back...")
                await self._remove_canary_traffic(config)
                await self._cleanup_canary_service(cluster_name, canary_service_name)
                return False
            
            # Step 6: Promote canary to full deployment
            logger.info("üéâ Canary successful, promoting to full deployment...")
            if not await self._promote_canary_to_full(cluster_name, service_name, new_task_def_arn, config):
                await self._remove_canary_traffic(config)
                await self._cleanup_canary_service(cluster_name, canary_service_name)
                return False
            
            # Step 7: Cleanup canary resources
            await self._cleanup_canary_service(cluster_name, canary_service_name)
            
            logger.info("‚úÖ Canary deployment completed successfully")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Canary deployment failed: {str(e)}")
            return False
    
    async def _rolling_deployment(self, config: DeploymentConfig, metrics: DeploymentMetrics) -> bool:
        """Execute rolling deployment strategy."""
        
        logger.info("üîÑ Executing Rolling deployment")
        
        cluster_name = f"praktiko-{config.environment}"
        service_name = f"praktiko-{config.service_name}-{config.environment}"
        
        try:
            # Step 1: Create new task definition
            logger.info("üìã Creating new task definition...")
            new_task_def_arn = await self._create_task_definition(config)
            if not new_task_def_arn:
                return False
            
            # Step 2: Update service with new task definition
            logger.info("üîÑ Updating service with new task definition...")
            
            response = self.ecs_client.update_service(
                cluster=cluster_name,
                service=service_name,
                taskDefinition=new_task_def_arn,
                deploymentConfiguration={
                    'minimumHealthyPercent': 50,
                    'maximumPercent': 200,
                    'deploymentCircuitBreaker': {
                        'enable': True,
                        'rollback': config.auto_rollback
                    }
                }
            )
            
            deployment_id = response['service']['deployments'][0]['id']
            logger.info(f"üìä Deployment ID: {deployment_id}")
            
            # Step 3: Monitor rolling deployment
            logger.info("‚è≥ Monitoring rolling deployment...")
            if not await self._monitor_rolling_deployment(
                cluster_name, service_name, deployment_id, config, metrics
            ):
                return False
            
            # Step 4: Final health check
            logger.info("ü©∫ Final health check...")
            service_endpoint = await self._get_service_endpoint(cluster_name, service_name)
            if not await self._comprehensive_health_check(service_endpoint, config, metrics):
                return False
            
            logger.info("‚úÖ Rolling deployment completed successfully")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Rolling deployment failed: {str(e)}")
            return False
    
    async def _fast_deployment(self, config: DeploymentConfig, metrics: DeploymentMetrics) -> bool:
        """Execute fast deployment strategy (for minor changes)."""
        
        logger.info("‚ö° Executing Fast deployment")
        
        # Fast deployment is essentially a rolling deployment with more aggressive settings
        cluster_name = f"praktiko-{config.environment}"
        service_name = f"praktiko-{config.service_name}-{config.environment}"
        
        try:
            # Step 1: Create new task definition
            new_task_def_arn = await self._create_task_definition(config)
            if not new_task_def_arn:
                return False
            
            # Step 2: Update service with aggressive deployment configuration
            response = self.ecs_client.update_service(
                cluster=cluster_name,
                service=service_name,
                taskDefinition=new_task_def_arn,
                deploymentConfiguration={
                    'minimumHealthyPercent': 100,
                    'maximumPercent': 200,
                    'deploymentCircuitBreaker': {
                        'enable': True,
                        'rollback': config.auto_rollback
                    }
                }
            )
            
            deployment_id = response['service']['deployments'][0]['id']
            
            # Step 3: Quick monitoring (shorter timeout)
            if not await self._monitor_rolling_deployment(
                cluster_name, service_name, deployment_id, config, metrics, timeout=180
            ):
                return False
            
            # Step 4: Basic health check
            service_endpoint = await self._get_service_endpoint(cluster_name, service_name)
            if not await self._basic_health_check(service_endpoint, config):
                return False
            
            logger.info("‚úÖ Fast deployment completed successfully")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Fast deployment failed: {str(e)}")
            return False
    
    async def _comprehensive_health_check(self, endpoint: str, config: DeploymentConfig, 
                                        metrics: DeploymentMetrics) -> bool:
        """Perform comprehensive health checks on the deployed service."""
        
        if not endpoint:
            logger.error("No endpoint available for health check")
            return False
        
        logger.info(f"ü©∫ Running comprehensive health checks on {endpoint}")
        
        # Health check endpoints
        health_endpoints = [
            {'path': config.health_check_path, 'name': 'Basic Health', 'critical': True},
            {'path': '/api/v1/health', 'name': 'API Health', 'critical': True},
            {'path': '/health/db', 'name': 'Database Health', 'critical': True},
            {'path': '/health/cache', 'name': 'Cache Health', 'critical': False},
            {'path': '/health/deps', 'name': 'Dependencies', 'critical': False},
            {'path': '/metrics', 'name': 'Metrics Endpoint', 'critical': False}
        ]
        
        start_time = time.time()
        
        while time.time() - start_time < config.health_check_timeout:
            all_critical_healthy = True
            healthy_endpoints = 0
            
            for endpoint_config in health_endpoints:
                url = f"{endpoint.rstrip('/')}{endpoint_config['path']}"
                
                try:
                    response = requests.get(url, timeout=10)
                    healthy = response.status_code == 200
                    
                    if healthy:
                        healthy_endpoints += 1
                        metrics.health_checks_passed += 1
                        logger.info(f"    ‚úÖ {endpoint_config['name']}: {response.status_code}")
                    else:
                        metrics.health_checks_failed += 1
                        logger.warning(f"    ‚ùå {endpoint_config['name']}: {response.status_code}")
                        if endpoint_config['critical']:
                            all_critical_healthy = False
                
                except Exception as e:
                    metrics.health_checks_failed += 1
                    logger.warning(f"    ‚ùå {endpoint_config['name']}: {str(e)}")
                    if endpoint_config['critical']:
                        all_critical_healthy = False
            
            if all_critical_healthy:
                success_rate = (healthy_endpoints / len(health_endpoints)) * 100
                logger.info(f"‚úÖ Health checks passed ({success_rate:.1f}% success rate)")
                return True
            
            logger.info(f"‚è≥ Waiting for health checks... ({int(time.time() - start_time)}s)")
            await asyncio.sleep(config.health_check_interval)
        
        logger.error(f"‚ùå Health checks failed after {config.health_check_timeout}s timeout")
        return False
    
    async def _basic_health_check(self, endpoint: str, config: DeploymentConfig) -> bool:
        """Perform basic health check (for fast deployments)."""
        
        if not endpoint:
            return False
        
        url = f"{endpoint.rstrip('/')}{config.health_check_path}"
        
        try:
            response = requests.get(url, timeout=10)
            healthy = response.status_code == 200
            
            if healthy:
                logger.info(f"‚úÖ Basic health check passed: {response.status_code}")
            else:
                logger.error(f"‚ùå Basic health check failed: {response.status_code}")
            
            return healthy
            
        except Exception as e:
            logger.error(f"‚ùå Basic health check failed: {str(e)}")
            return False
    
    # Additional helper methods would be implemented here...
    # (Due to length constraints, showing the core structure)
    
    async def _create_task_definition(self, config: DeploymentConfig) -> Optional[str]:
        """Create new ECS task definition."""
        # Implementation would create and register a new task definition
        logger.info("Creating task definition...")
        return f"arn:aws:ecs:{self.region}:123456789012:task-definition/{config.service_name}:1"
    
    async def _get_service_endpoint(self, cluster_name: str, service_name: str) -> Optional[str]:
        """Get service endpoint URL."""
        # Implementation would get the actual service endpoint
        return f"https://api-{service_name}.praktiko.ai"
    
    async def _save_deployment_record(self, config: DeploymentConfig, 
                                    metrics: DeploymentMetrics, success: bool):
        """Save deployment record for audit and analysis."""
        
        record = {
            'timestamp': datetime.utcnow().isoformat(),
            'service_name': config.service_name,
            'environment': config.environment,
            'strategy': config.strategy.value,
            'image_uri': config.image_uri,
            'success': success,
            'duration': metrics.duration,
            'health_checks_passed': metrics.health_checks_passed,
            'health_checks_failed': metrics.health_checks_failed,
            'rollback_triggered': metrics.rollback_triggered
        }
        
        self.deployment_history.append(record)
        
        # Save to file
        with open(f'deployment-history-{config.environment}.json', 'w') as f:
            json.dump(self.deployment_history, f, indent=2)
        
        logger.info(f"üìù Deployment record saved: {record}")
    
    async def _send_notifications(self, config: DeploymentConfig, 
                                metrics: DeploymentMetrics, success: bool):
        """Send deployment notifications."""
        
        status = "‚úÖ SUCCESS" if success else "‚ùå FAILED"
        duration = f"{metrics.duration:.1f}s" if metrics.duration else "N/A"
        
        message = f"""
üöÄ **Deployment {status}**

**Service:** {config.service_name}
**Environment:** {config.environment}
**Strategy:** {config.strategy.value}
**Duration:** {duration}
**Health Checks:** {metrics.health_checks_passed}‚úÖ / {metrics.health_checks_failed}‚ùå
        """
        
        if config.slack_webhook:
            try:
                requests.post(config.slack_webhook, json={'text': message})
                logger.info("üì± Slack notification sent")
            except Exception as e:
                logger.warning(f"Failed to send Slack notification: {e}")
        
        logger.info(f"üì¢ Deployment notification: {message}")


async def main():
    """Main entry point for deployment script."""
    
    parser = argparse.ArgumentParser(description='Advanced Zero-Downtime Deployment System')
    parser.add_argument('--service', required=True, help='Service name to deploy')
    parser.add_argument('--environment', required=True, help='Target environment')
    parser.add_argument('--image', required=True, help='Container image URI')
    parser.add_argument('--strategy', required=True, choices=['rolling', 'blue-green', 'canary', 'fast'],
                       help='Deployment strategy')
    parser.add_argument('--desired-count', type=int, default=2, help='Desired instance count')
    parser.add_argument('--region', default='us-east-1', help='AWS region')
    parser.add_argument('--auto-rollback', action='store_true', help='Enable auto rollback')
    parser.add_argument('--slack-webhook', help='Slack webhook URL for notifications')
    
    args = parser.parse_args()
    
    # Create deployment configuration
    config = DeploymentConfig(
        service_name=args.service,
        environment=args.environment,
        image_uri=args.image,
        strategy=DeploymentStrategy(args.strategy),
        desired_count=args.desired_count,
        auto_rollback=args.auto_rollback,
        slack_webhook=args.slack_webhook
    )
    
    # Execute deployment
    deployment_manager = AWSDeploymentManager(region=args.region)
    success = await deployment_manager.deploy(config)
    
    # Exit with appropriate code
    sys.exit(0 if success else 1)


if __name__ == '__main__':
    asyncio.run(main())