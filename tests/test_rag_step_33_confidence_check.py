#!/usr/bin/env python3
"""
Tests for RAG STEP 33 â€” Confidence at least threshold?

This step performs a confidence threshold check on classification results.
"""

from datetime import datetime
from unittest.mock import MagicMock, patch

import pytest

from app.orchestrators.classify import step_33__confidence_check
from app.services.domain_action_classifier import Domain, Action


class TestRAGStep33ConfidenceCheck:
    """Test suite for RAG STEP 33 - Confidence threshold check"""

    @pytest.mark.asyncio
    @patch('app.orchestrators.classify.rag_step_log')
    @patch('app.core.logging.logger')
    async def test_step_33_confidence_above_threshold(self, mock_logger, mock_rag_log):
        """Test Step 33: Confidence above threshold (default 0.6)"""

        ctx = {
            'classification': {
                'domain': 'tax',
                'action': 'information_request',
                'confidence': 0.85,
                'fallback_used': False
            }
        }

        # Call the orchestrator function
        result = await step_33__confidence_check(ctx=ctx)

        # Verify the result structure
        assert isinstance(result, dict)
        assert result['confidence_met'] is True
        assert result['confidence_value'] == 0.85
        assert result['threshold'] == 0.6
        assert result['domain'] == 'tax'
        assert result['action'] == 'information_request'
        assert 'timestamp' in result

        # Verify logging was called
        mock_logger.info.assert_called_once()
        log_call = mock_logger.info.call_args
        assert 'Confidence threshold met' in log_call[0][0]
        assert log_call[1]['extra']['confidence_event'] == 'threshold_met'
        assert log_call[1]['extra']['confidence_value'] == 0.85

    @pytest.mark.asyncio
    @patch('app.orchestrators.classify.rag_step_log')
    @patch('app.core.logging.logger')
    async def test_step_33_confidence_below_threshold(self, mock_logger, mock_rag_log):
        """Test Step 33: Confidence below threshold"""

        ctx = {
            'classification': {
                'domain': 'business',
                'action': 'strategic_advice',
                'confidence': 0.45,
                'fallback_used': False
            }
        }

        result = await step_33__confidence_check(ctx=ctx)

        assert result['confidence_met'] is False
        assert result['confidence_value'] == 0.45
        assert result['threshold'] == 0.6

        # Verify warning was logged
        mock_logger.warning.assert_called_once()
        warning_call = mock_logger.warning.call_args
        assert 'Confidence threshold not met' in warning_call[0][0]

    @pytest.mark.asyncio
    @patch('app.orchestrators.classify.rag_step_log')
    @patch('app.core.logging.logger')
    async def test_step_33_custom_threshold(self, mock_logger, mock_rag_log):
        """Test Step 33: Custom confidence threshold"""

        ctx = {
            'classification': {
                'domain': 'legal',
                'action': 'document_generation',
                'confidence': 0.75,
                'fallback_used': False
            },
            'confidence_threshold': 0.8
        }

        result = await step_33__confidence_check(ctx=ctx)

        assert result['confidence_met'] is False
        assert result['confidence_value'] == 0.75
        assert result['threshold'] == 0.8

    @pytest.mark.asyncio
    @patch('app.orchestrators.classify.rag_step_log')
    @patch('app.core.logging.logger')
    async def test_step_33_exact_threshold_match(self, mock_logger, mock_rag_log):
        """Test Step 33: Confidence exactly at threshold"""

        ctx = {
            'classification': {
                'domain': 'accounting',
                'action': 'calculation_request',
                'confidence': 0.6,
                'fallback_used': False
            }
        }

        result = await step_33__confidence_check(ctx=ctx)

        assert result['confidence_met'] is True
        assert result['confidence_value'] == 0.6
        assert result['threshold'] == 0.6

    @pytest.mark.asyncio
    @patch('app.orchestrators.classify.rag_step_log')
    @patch('app.core.logging.logger')
    async def test_step_33_missing_classification(self, mock_logger, mock_rag_log):
        """Test Step 33: Handle missing classification"""

        ctx = {}

        result = await step_33__confidence_check(ctx=ctx)

        # Should return error result
        assert result['confidence_met'] is False
        assert result['error'] == 'No classification data provided'
        assert result['confidence_value'] == 0.0

        # Verify error was logged
        mock_logger.error.assert_called_once()
        error_call = mock_logger.error.call_args
        assert 'Confidence check failed' in error_call[0][0]

    @pytest.mark.asyncio
    @patch('app.orchestrators.classify.rag_step_log')
    @patch('app.core.logging.logger')
    async def test_step_33_confidence_from_scores(self, mock_logger, mock_rag_log):
        """Test Step 33: Use confidence from scores data when classification missing"""

        ctx = {
            'scores_data': {
                'domain_confidence': 0.85,
                'action_confidence': 0.90,
                'best_domain': Domain.TAX,
                'best_action': Action.INFORMATION_REQUEST
            }
        }

        result = await step_33__confidence_check(ctx=ctx)

        # Should use domain confidence as primary
        assert result['confidence_met'] is True
        assert result['confidence_value'] == 0.85
        assert result['domain'] == 'tax'
        assert result['action'] == 'information_request'

    @pytest.mark.asyncio
    @patch('app.orchestrators.classify.rag_step_log')
    @patch('app.core.logging.logger')
    async def test_step_33_fallback_detected(self, mock_logger, mock_rag_log):
        """Test Step 33: LLM fallback used in classification"""

        ctx = {
            'classification': {
                'domain': 'labor',
                'action': 'compliance_check',
                'confidence': 0.75,
                'fallback_used': True
            }
        }

        result = await step_33__confidence_check(ctx=ctx)

        assert result['confidence_met'] is True
        assert result['fallback_used'] is True

        # Verify fallback was noted in logging
        mock_logger.info.assert_called_once()
        log_call = mock_logger.info.call_args
        assert log_call[1]['extra']['fallback_used'] is True

    @pytest.mark.asyncio
    @patch('app.orchestrators.classify.rag_step_log')
    @patch('app.core.logging.logger')
    async def test_step_33_kwargs_parameters(self, mock_logger, mock_rag_log):
        """Test Step 33: Parameters passed via kwargs"""

        # Call with kwargs instead of ctx
        result = await step_33__confidence_check(
            classification={
                'domain': 'tax',
                'confidence': 0.88
            },
            confidence_threshold=0.7
        )

        # Verify kwargs are processed correctly
        assert result['confidence_met'] is True
        assert result['confidence_value'] == 0.88
        assert result['threshold'] == 0.7

    @pytest.mark.asyncio
    @patch('app.orchestrators.classify.rag_step_log')
    @patch('app.core.logging.logger')
    async def test_step_33_performance_tracking(self, mock_logger, mock_rag_log):
        """Test Step 33: Performance tracking with timer"""

        with patch('app.orchestrators.classify.rag_step_timer') as mock_timer:
            # Mock the timer context manager
            mock_timer.return_value.__enter__ = MagicMock()
            mock_timer.return_value.__exit__ = MagicMock()

            # Call the orchestrator function
            await step_33__confidence_check(ctx={'classification': {'confidence': 0.8}})

            # Verify timer was used
            mock_timer.assert_called_with(
                33,
                'RAG.classify.confidence.at.least.threshold',
                'ConfidenceCheck',
                stage='start'
            )

    @pytest.mark.asyncio
    @patch('app.orchestrators.classify.rag_step_log')
    @patch('app.core.logging.logger')
    async def test_step_33_comprehensive_logging_format(self, mock_logger, mock_rag_log):
        """Test Step 33: Verify comprehensive logging format"""

        ctx = {
            'classification': {
                'domain': 'tax',
                'action': 'information_request',
                'confidence': 0.85,
                'fallback_used': False
            }
        }

        # Call the orchestrator function
        await step_33__confidence_check(ctx=ctx)

        # Verify RAG step logging format
        completed_logs = [
            call for call in mock_rag_log.call_args_list
            if call[1].get('processing_stage') == 'completed'
        ]

        assert len(completed_logs) > 0
        log_call = completed_logs[0]

        # Check required fields
        required_fields = [
            'step', 'step_id', 'node_label', 'confidence_event',
            'confidence_met', 'confidence_value', 'threshold', 'domain', 'action',
            'processing_stage'
        ]

        for field in required_fields:
            assert field in log_call[1], f"Missing required field: {field}"

        # Verify specific values
        assert log_call[1]['step'] == 33
        assert log_call[1]['step_id'] == 'RAG.classify.confidence.at.least.threshold'
        assert log_call[1]['node_label'] == 'ConfidenceCheck'
        assert log_call[1]['confidence_event'] == 'threshold_met'

    @pytest.mark.asyncio
    @patch('app.orchestrators.classify.rag_step_log')
    @patch('app.core.logging.logger')
    async def test_step_33_confidence_data_structure(self, mock_logger, mock_rag_log):
        """Test Step 33: Verify confidence data structure"""

        ctx = {
            'classification': {
                'domain': 'tax',
                'action': 'information_request',
                'confidence': 0.85,
                'fallback_used': False
            }
        }

        # Call the orchestrator function
        result = await step_33__confidence_check(ctx=ctx)

        # Verify all expected fields in result
        expected_fields = [
            'timestamp', 'confidence_met', 'confidence_value', 'threshold',
            'domain', 'action', 'fallback_used', 'error'
        ]

        for field in expected_fields:
            assert field in result, f"Missing field in confidence data: {field}"

        # Verify data types
        assert isinstance(result['timestamp'], str)
        assert isinstance(result['confidence_met'], bool)
        assert isinstance(result['confidence_value'], float)
        assert isinstance(result['threshold'], float)
        assert isinstance(result['domain'], str) or result['domain'] is None
        assert isinstance(result['action'], str) or result['action'] is None
        assert isinstance(result['fallback_used'], bool)

        # Verify timestamp format (ISO format)
        datetime.fromisoformat(result['timestamp'].replace('Z', '+00:00'))